{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T09:46:37.496456Z",
     "start_time": "2019-11-17T09:46:36.784665Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.utils.data模块提供了有关数据处理的工具\n",
    "- torch.nn模块定义了大量神经网络的层\n",
    "- torch.nn.init模块定义了各种初始化方法\n",
    "- torch.optim模块提供了模型参数初始化的各种方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习率的调整\n",
    "\n",
    "```\n",
    "optimizer =optim.SGD([\n",
    "    # 如果对某个参数不指定学习率，就使用最外层的默认学习率\n",
    "    {'params': net.subnet1.parameters()}, # lr=0.03\n",
    "    {'params': net.subnet2.parameters(), 'lr': 0.01}\n",
    "], lr=0.03)\n",
    "```\n",
    "有时候我们不想让学习率固定成一个常数，那如何调整学习率呢？主要有两种做法。一种是修改optimizer.param_groups中对应的学习率，另一种是更简单也是较为推荐的做法——新建优化器，由于optimizer十分轻量级，构建开销很小，故而可以构建新的optimizer。但是后者对于使用动量的优化器（如Adam），会丢失动量等状态信息，可能会造成损失函数的收敛出现震荡等情况。\n",
    "\n",
    "```\n",
    "# 调整学习率\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] *= 0.1 # 学习率为之前的0.1倍\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T09:52:37.880256Z",
     "start_time": "2019-11-17T09:52:37.871282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 写法一\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 1)\n",
    ")\n",
    "\n",
    "# 写法二\n",
    "net = torch.nn.Sequential()\n",
    "net.add_module('linear', torch.nn.Linear(2, 1))\n",
    "# net.add_module ......\n",
    "\n",
    "# 写法三\n",
    "from collections import OrderedDict\n",
    "net = torch.nn.Sequential(OrderedDict([\n",
    "    ('linear', torch.nn.Linear(2, 1))\n",
    "    # ......\n",
    "]))\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数的相关\n",
    "\n",
    "net[0] 这样根据下标访问子模块的写法只有当 net 是个 ModuleList 或者 Sequential 实例时才可以"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T09:47:30.195677Z",
     "start_time": "2019-11-17T09:47:30.188790Z"
    }
   },
   "outputs": [],
   "source": [
    "class LinearNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_features=2, out_features=1, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "net = LinearNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T09:47:30.320375Z",
     "start_time": "2019-11-17T09:47:30.308336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.0266, 0.0058]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "## 初始化参数\n",
    "torch.nn.init.normal_(net.linear.weight, 0., 0.1)\n",
    "torch.nn.init.constant_(net.linear.bias, 0.)\n",
    "\n",
    "## 查看参数\n",
    "for param in net.parameters():\n",
    "    print(param)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T09:52:18.318198Z",
     "start_time": "2019-11-17T09:52:18.306295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "Linear(in_features=2, out_features=1, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.7035,  0.5380]], requires_grad=True) Parameter containing:\n",
      "tensor([0.3234], requires_grad=True)\n",
      "[Parameter containing:\n",
      "tensor([[-0.7035,  0.5380]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3234], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 1)\n",
    ")\n",
    "\n",
    "print(net)\n",
    "print(net[0])\n",
    "print(net[0].weight, net[0].bias)\n",
    "print(list(net[0].parameters()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T09:53:48.535084Z",
     "start_time": "2019-11-17T09:53:48.527004Z"
    }
   },
   "source": [
    "### 其它\n",
    "\n",
    "注意：torch.nn仅支持输入一个batch的样本不支持单个样本输入，如果只有单个样本，可使用input.unsqueeze(0)来添加一维。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T09:54:31.381070Z",
     "start_time": "2019-11-17T09:54:31.373078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.])\n",
      "tensor([[1., 2.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([1.,2.]))\n",
    "print(torch.tensor([1.,2.]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
