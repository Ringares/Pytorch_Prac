{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T12:54:31.516680Z",
     "start_time": "2019-11-23T12:54:30.302347Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 确认运行设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T12:54:31.529625Z",
     "start_time": "2019-11-23T12:54:31.519136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T12:12:50.708102Z",
     "start_time": "2019-11-23T12:12:50.705688Z"
    }
   },
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T12:54:31.543572Z",
     "start_time": "2019-11-23T12:54:31.534667Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('./data/jaychou_lyrics.txt', 'r') as f:\n",
    "    corpus = f.read()\n",
    "    corpus = corpus.replace('\\n', ' ').replace('\\u3000', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T12:54:31.559573Z",
     "start_time": "2019-11-23T12:54:31.546864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1027"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = corpus[:10000]\n",
    "idx_to_char = list(set(corpus))\n",
    "vocab_size = len(idx_to_char)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T12:54:31.567897Z",
     "start_time": "2019-11-23T12:54:31.562769Z"
    }
   },
   "outputs": [],
   "source": [
    "char_to_idx = {c:i for i, c in enumerate(idx_to_char)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:03:22.253211Z",
     "start_time": "2019-11-20T10:03:22.238437Z"
    }
   },
   "source": [
    "#### 时序数据的采样\n",
    "\n",
    "不同的采样方式, 在训练实现上会略有不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T12:54:31.583855Z",
     "start_time": "2019-11-23T12:54:31.570760Z"
    }
   },
   "outputs": [],
   "source": [
    "# 随机采样 每次采样前都需要重新初始化隐藏状态\n",
    "def data_iter_random(corpus_indices, batch_size, window, device):\n",
    "    num_example = (len(corpus_indices)-1) // window\n",
    "    batch_num = num_example // batch_size\n",
    "    \n",
    "    example_indices = list(range(num_example))\n",
    "    random.shuffle(example_indices)\n",
    "    \n",
    "    for i in range(batch_num):\n",
    "        batch_indices = example_indices[i*batch_size: (i+1)*batch_size]\n",
    "        train_example = [corpus_indices[j*window: (j+1)*window] for j in batch_indices]\n",
    "        test_example = [corpus_indices[j*window+1: (j+1)*window+1] for j in batch_indices]\n",
    "        yield torch.tensor(train_example, dtype=torch.float32, device=device), torch.tensor(test_example, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T12:54:31.599659Z",
     "start_time": "2019-11-23T12:54:31.586711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "X:  tensor([[12., 13., 14., 15., 16., 17.],\n",
      "        [18., 19., 20., 21., 22., 23.]]) \n",
      "Y: tensor([[13., 14., 15., 16., 17., 18.],\n",
      "        [19., 20., 21., 22., 23., 24.]]) \n",
      "\n",
      "X:  tensor([[ 6.,  7.,  8.,  9., 10., 11.],\n",
      "        [ 0.,  1.,  2.,  3.,  4.,  5.]]) \n",
      "Y: tensor([[ 7.,  8.,  9., 10., 11., 12.],\n",
      "        [ 1.,  2.,  3.,  4.,  5.,  6.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_seq = list(range(30))\n",
    "print(my_seq)\n",
    "for X, Y in data_iter_random(my_seq, batch_size=2, window=6, device=device):\n",
    "    print('X: ', X, '\\nY:', Y, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T12:54:31.611081Z",
     "start_time": "2019-11-23T12:54:31.604491Z"
    }
   },
   "outputs": [],
   "source": [
    "# 相邻采样\n",
    "def data_iter_consecutive(corpus_indices, batch_size, window, device):\n",
    "    batch_len = len(corpus_indices) // batch_size\n",
    "    corpus_indices = torch.tensor(corpus_indices, dtype=torch.float32, device=device)\n",
    "    corpus_indices = corpus_indices[0:batch_len*batch_size]\n",
    "    corpus_indices = corpus_indices.view(batch_size, batch_len)\n",
    "    \n",
    "    batch_num = (batch_len-1)//window\n",
    "    for i in range(batch_num):\n",
    "        train_example = corpus_indices[:,i*window:(i+1)*window]\n",
    "        test_example = corpus_indices[:,i*window+1:(i+1)*window+1]\n",
    "        yield train_example, test_example\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T12:54:31.627253Z",
     "start_time": "2019-11-23T12:54:31.613574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "X:  tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "        [15., 16., 17., 18., 19., 20.]]) \n",
      "Y: tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [16., 17., 18., 19., 20., 21.]]) \n",
      "\n",
      "X:  tensor([[ 6.,  7.,  8.,  9., 10., 11.],\n",
      "        [21., 22., 23., 24., 25., 26.]]) \n",
      "Y: tensor([[ 7.,  8.,  9., 10., 11., 12.],\n",
      "        [22., 23., 24., 25., 26., 27.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_seq = list(range(30))\n",
    "print(my_seq)\n",
    "for X, Y in data_iter_consecutive(my_seq, batch_size=2, window=6, device=device):\n",
    "    print('X: ', X, '\\nY:', Y, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T12:13:09.825080Z",
     "start_time": "2019-11-23T12:13:09.822491Z"
    }
   },
   "source": [
    "#### onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T12:54:31.634159Z",
     "start_time": "2019-11-23T12:54:31.629302Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot(x, n_class, dtype=torch.float32):\n",
    "    x = x.long()\n",
    "    res = torch.zeros(x.shape[0], n_class, dtype=dtype, device=x.device)\n",
    "    res.scatter_(1, x.view(-1,1), 1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T12:54:31.643396Z",
     "start_time": "2019-11-23T12:54:31.636348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.,2.])\n",
    "one_hot(x, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T12:54:31.655159Z",
     "start_time": "2019-11-23T12:54:31.647847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 0]],\n",
       "\n",
       "        [[0, 0, 1]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.one_hot(x.long().view(-1,1), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T12:14:18.570986Z",
     "start_time": "2019-11-23T12:14:18.568418Z"
    }
   },
   "source": [
    "### Define RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T12:54:31.662586Z",
     "start_time": "2019-11-23T12:54:31.657808Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_onehot(x_batch, n_class=vocab_size):\n",
    "    \"\"\"\n",
    "    x_batch: batch x seq_len\n",
    "    return: [tensor(batch, n_class), ...] x sql_len\n",
    "    \"\"\"\n",
    "    return [one_hot(x_batch[:,i] , n_class) for i in range(x_batch.shape[1])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T13:23:39.079634Z",
     "start_time": "2019-11-23T13:23:39.073384Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_params(num_inputs, num_hiddens, num_outputs, device=device):\n",
    "    \"\"\"\n",
    "    initialize params\n",
    "    \"\"\"\n",
    "    def _randn(shape):\n",
    "        return torch.nn.Parameter(\n",
    "            torch.tensor(np.random.normal(0, 0.01, size=shape), dtype=torch.float32, device=device)\n",
    "        )\n",
    "    \n",
    "    def _zero(size):\n",
    "        return torch.nn.Parameter(torch.zeros(size, device=device))\n",
    "    \n",
    "    W_xh = _randn((num_inputs, num_hiddens))\n",
    "    W_hh = _randn((num_hiddens, num_hiddens))\n",
    "    W_hq = _randn((num_hiddens, num_outputs))\n",
    "    \n",
    "    b_h = _zero(num_hiddens)\n",
    "    b_q = _zero(num_outputs)\n",
    "    \n",
    "    return torch.nn.ParameterList([W_xh, W_hh, W_hq, b_h, b_q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T13:23:39.566808Z",
     "start_time": "2019-11-23T13:23:39.563753Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_hiden_state(batch_size, num_hiddens, device):\n",
    "    return torch.zeros((batch_size, num_hiddens), device=device)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T13:23:40.060943Z",
     "start_time": "2019-11-23T13:23:40.056725Z"
    }
   },
   "outputs": [],
   "source": [
    "def rnn(inputs, hidden_state, params):\n",
    "    \"\"\"\n",
    "    return outputs, hidden_state\n",
    "    \"\"\"\n",
    "    W_xh, W_hh, W_hq, b_h, b_q = params\n",
    "    outputs = []\n",
    "    for batch_x in inputs:\n",
    "        hidden_state = torch.tanh(torch.mm(batch_x, W_xh) + torch.mm(hidden_state, W_hh) + b_h)\n",
    "        outputs.append(torch.mm(hidden_state, W_hq) + b_q)\n",
    "    return outputs, hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T13:23:58.249379Z",
     "start_time": "2019-11-23T13:23:58.219975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 torch.Size([2, 1027])\n",
      "torch.Size([2, 256])\n",
      "5 torch.Size([2, 1027]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# test size\n",
    "X = torch.arange(10).view(2, 5)\n",
    "inputs = to_onehot(X, vocab_size)\n",
    "print(len(inputs), inputs[0].shape)\n",
    "\n",
    "hidden_state = init_hiden_state(2, num_hiddens, device)\n",
    "print(hidden_state.shape)\n",
    "outputs, hidden_state = rnn(inputs, hidden_state, get_params(vocab_size, 256, vocab_size, device))\n",
    "print(len(outputs), outputs[0].shape, hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T12:54:31.799561Z",
     "start_time": "2019-11-23T12:54:31.755558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'分开移戒飞早柳拿提跑告近'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_rnn(prefix, \n",
    "                num_chars, \n",
    "                rnn, \n",
    "                params, \n",
    "                init_hiden_state_func, \n",
    "                num_hiddens, \n",
    "                vocab_size, \n",
    "                device, \n",
    "                idx_to_char, \n",
    "                char_to_idx):\n",
    "    H = init_hiden_state_func(1, num_hiddens, device)\n",
    "    outputs = [char_to_idx[prefix[0]]]\n",
    "    for i in range(1, num_chars+len(prefix)):\n",
    "        X = to_onehot(torch.tensor(outputs[-1]).view(1,-1))\n",
    "        Y, state = rnn(X, H, params)\n",
    "        \n",
    "        if i <= len(prefix)-1:\n",
    "            outputs.append(char_to_idx[prefix[i]])\n",
    "        else:\n",
    "            outputs.append(int(Y[0].argmax(dim=1).item()))\n",
    "    return ''.join([idx_to_char[i] for i in outputs])\n",
    "        \n",
    "    \n",
    "predict_rnn('分开', 10, rnn, get_params(), init_hiden_state, num_hiddens, vocab_size,\n",
    "            device, idx_to_char, char_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T12:14:44.128276Z",
     "start_time": "2019-11-23T12:14:44.125798Z"
    }
   },
   "source": [
    "### Train RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T13:54:21.726404Z",
     "start_time": "2019-11-23T13:54:21.718360Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = x - x.max(dim=1, keepdim=True).values\n",
    "    return x.exp() / x.exp().sum(dim=1, keepdim=True)\n",
    "\n",
    "def cross_entropy_loss(y, y_hat):\n",
    "    \"\"\"\n",
    "    y=[0,1,2]\n",
    "    y_hat = [\n",
    "        [0.7,0.2,0.1],\n",
    "        [0.2,0.5,0.3],\n",
    "        [0.1,0.1,0.8],\n",
    "    ]\n",
    "    \"\"\"\n",
    "    y_hat = softmax(y_hat)\n",
    "    return -torch.log(\n",
    "        y_hat.gather(dim=1, index=y.type(torch.long).view(-1,1))+1e-5\n",
    "    ).sum()\n",
    "\n",
    "def sgd(params, lr, bs):\n",
    "    for param in params:\n",
    "        param.data -= param.grad / bs * lr\n",
    "        \n",
    "def grad_clipping(params, theta, device):\n",
    "    norm = torch.tensor([0.0], device=device)\n",
    "    for param in params:\n",
    "        norm += (param.grad.data ** 2).sum()\n",
    "    norm = norm.sqrt().item()\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad.data *= (theta / norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T15:11:37.223815Z",
     "start_time": "2019-11-23T15:06:32.976612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, perplexity 1.036188, time 1.58 sec\n",
      " - 分开                                                  \n",
      " - 不分开                                                  \n",
      "epoch 20, perplexity 1.035752, time 1.28 sec\n",
      " - 分开                                                  \n",
      " - 不分开                                                  \n",
      "epoch 30, perplexity 1.035588, time 1.25 sec\n",
      " - 分开                                                  \n",
      " - 不分开                                                  \n",
      "epoch 40, perplexity 1.035387, time 1.83 sec\n",
      " - 分开                                                  \n",
      " - 不分开                                                  \n",
      "epoch 50, perplexity 1.035164, time 1.11 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      "epoch 60, perplexity 1.035050, time 1.21 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      "epoch 70, perplexity 1.034913, time 1.03 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      "epoch 80, perplexity 1.034774, time 1.13 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      "epoch 90, perplexity 1.034595, time 1.12 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      "epoch 100, perplexity 1.034427, time 1.36 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      "epoch 110, perplexity 1.034250, time 1.23 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      "epoch 120, perplexity 1.034055, time 1.04 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      "epoch 130, perplexity 1.033857, time 1.08 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      "epoch 140, perplexity 1.033642, time 1.09 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      "epoch 150, perplexity 1.033419, time 1.09 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      "epoch 160, perplexity 1.033163, time 1.08 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      "epoch 170, perplexity 1.032914, time 1.46 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      "epoch 180, perplexity 1.032683, time 1.30 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      "epoch 190, perplexity 1.032434, time 1.29 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      "epoch 200, perplexity 1.032174, time 1.08 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      "epoch 210, perplexity 1.031918, time 1.07 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      "epoch 220, perplexity 1.031701, time 1.10 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      "epoch 230, perplexity 1.031501, time 1.93 sec\n",
      " - 分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n",
      " - 不分开 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我 我\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-b0e0db174eb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mpred_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefixes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'分开'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'不分开'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclipping_theta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hiddens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_rand_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-121-b0e0db174eb4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_iter, params, num_epochs, batch_size, lr, clipping_theta, num_hiddens, vocab_size, device, is_rand_sample)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_hiden_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# y_hat: list of bs x vocab_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-e6f38b7cecb8>\u001b[0m in \u001b[0;36mto_onehot\u001b[0;34m(x_batch, n_class)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mx\u001b[0m \u001b[0msql_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mn_class\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-e6f38b7cecb8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mx\u001b[0m \u001b[0msql_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mn_class\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-35141ee3d5dd>\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(x, n_class, dtype)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time, math\n",
    "\n",
    "def train(data_iter, \n",
    "          params, \n",
    "          num_epochs, \n",
    "          batch_size, \n",
    "          lr, \n",
    "          clipping_theta, \n",
    "          num_hiddens, \n",
    "          vocab_size, \n",
    "          device, \n",
    "          is_rand_sample=True):\n",
    "    H = init_hiden_state(batch_size, num_hiddens, device)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        l_sum, n, start = 0.0, 0, time.time()\n",
    "        \n",
    "        for X, Y in data_iter():\n",
    "            if is_rand_sample:\n",
    "                H = init_hiden_state(batch_size, num_hiddens, device)\n",
    "\n",
    "            inputs = to_onehot(X, vocab_size)\n",
    "            y_hat, H = rnn(inputs, H, params) # y_hat: list of bs x vocab_size\n",
    "            y_hat = torch.cat(y_hat, dim=0)\n",
    "            y = Y.T.reshape(-1)\n",
    "            l = loss(y_hat, y.long())\n",
    "\n",
    "            for param in params:\n",
    "                if param.grad is not None:\n",
    "                    param.grad.data.zero_()\n",
    "\n",
    "            l.backward()\n",
    "            grad_clipping(params, clipping_theta, device)  # 裁剪梯度\n",
    "            sgd(params, lr, batch_size)\n",
    "            l_sum += l.item()\n",
    "            n += y.shape[0]\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print('epoch %d, perplexity %f, time %.2f sec' % (\n",
    "                epoch + 1, math.exp(l_sum / n), time.time() - start))\n",
    "            for prefix in prefixes:\n",
    "                print(' -', predict_rnn(prefix, pred_len, rnn, params, init_hiden_state,\n",
    "                                        num_hiddens, vocab_size, device, idx_to_char, char_to_idx))\n",
    "            \n",
    "    \n",
    "\n",
    "data_iter = lambda : data_iter_random([char_to_idx[i] for i in corpus], 32, 5, device)\n",
    "params = get_params(vocab_size, 256, vocab_size, device)\n",
    "pred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']\n",
    "train(data_iter, params, 1000, 32, lr=1e2, clipping_theta=1e-2, num_hiddens=256, vocab_size=vocab_size, device=device, is_rand_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T14:04:12.554575Z",
     "start_time": "2019-11-23T14:04:12.550653Z"
    }
   },
   "outputs": [],
   "source": [
    "data_iter = lambda : data_iter_random([char_to_idx[i] for i in corpus], 32, 5, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T14:45:06.111419Z",
     "start_time": "2019-11-23T14:45:06.041196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'分开衫怨狗彻跑联然守演连队前枯点画亏童裂社轻丛决送拿命没术透缘念忆始阻明边再鼻伯或朵瓦濡准去替狠选斯如再'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = get_params(vocab_size, 256, vocab_size)\n",
    "predict_rnn('分开', pred_len, rnn, params, init_hiden_state, 256, vocab_size, device, idx_to_char, char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T14:40:25.234390Z",
     "start_time": "2019-11-23T14:40:25.230127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ParameterList(\n",
       "     (0): Parameter containing: [torch.FloatTensor of size 1027x100]\n",
       "     (1): Parameter containing: [torch.FloatTensor of size 100x100]\n",
       "     (2): Parameter containing: [torch.FloatTensor of size 100x1027]\n",
       "     (3): Parameter containing: [torch.FloatTensor of size 100]\n",
       "     (4): Parameter containing: [torch.FloatTensor of size 1027]\n",
       " ), 256)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params, num_hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T15:11:40.501052Z",
     "start_time": "2019-11-23T15:11:40.489026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0236,  0.0084,  0.0050,  ..., -0.0085, -0.0084, -0.0057],\n",
      "        [ 0.0008, -0.0047, -0.0096,  ...,  0.0216, -0.0160, -0.0103],\n",
      "        [-0.0015,  0.0093,  0.0154,  ...,  0.0038, -0.0141,  0.0162],\n",
      "        ...,\n",
      "        [-0.0043,  0.0201,  0.0048,  ...,  0.0221, -0.0079,  0.0193],\n",
      "        [-0.0096,  0.0008,  0.0056,  ..., -0.0123,  0.0009,  0.0089],\n",
      "        [ 0.0082,  0.0049,  0.0021,  ...,  0.0048, -0.0014, -0.0015]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0723, -0.0493,  0.0366,  ...,  0.0056,  0.0715, -0.0638],\n",
      "        [-0.0122, -0.0020,  0.0081,  ..., -0.0375, -0.0039,  0.0348],\n",
      "        [ 0.0374, -0.0103, -0.0039,  ...,  0.0052, -0.0053,  0.0388],\n",
      "        ...,\n",
      "        [ 0.0471, -0.0073, -0.0082,  ...,  0.0012,  0.0024,  0.0048],\n",
      "        [ 0.0132, -0.0262, -0.0012,  ..., -0.0078,  0.0055, -0.0061],\n",
      "        [-0.0080,  0.0199,  0.0087,  ..., -0.0080, -0.0020,  0.0204]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0006, -0.0380, -0.0175,  ...,  0.0121,  0.0134, -0.0382],\n",
      "        [-0.0085, -0.0065,  0.0027,  ..., -0.0184, -0.0025,  0.0078],\n",
      "        [-0.0233,  0.0083, -0.0363,  ...,  0.0066,  0.0130, -0.0498],\n",
      "        ...,\n",
      "        [ 0.0024,  0.0036,  0.0132,  ...,  0.0232, -0.0144, -0.0049],\n",
      "        [ 0.0243, -0.0283,  0.0079,  ..., -0.0347, -0.0231,  0.0222],\n",
      "        [ 0.0049, -0.0089, -0.0153,  ..., -0.0198, -0.0028, -0.0093]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0542,  0.2297, -0.3470, -0.1313,  0.0093,  0.2082,  0.3795,  0.0955,\n",
      "        -0.4549, -0.0260,  0.6624, -0.2135,  0.4457, -0.2428, -0.2316, -0.0979,\n",
      "         0.2838, -0.2870,  0.1744, -0.3726,  0.4740, -0.0640,  0.1279, -0.3994,\n",
      "         0.0413, -0.2947,  0.3156, -0.2401, -0.4884, -0.1870, -0.1865, -0.2560,\n",
      "         0.6155,  0.5453, -0.0583,  0.1019, -0.0189,  0.1802,  0.2424, -0.5029,\n",
      "        -0.1081,  0.3889,  0.4655, -0.2200, -0.4381, -0.0183,  0.3377,  0.1052,\n",
      "         0.1573,  0.2741, -0.1746,  0.0869, -0.2725, -0.1200, -0.0720, -0.2089,\n",
      "         0.1356, -0.3458,  0.1374,  0.0367,  0.3865,  0.0893, -0.1000, -0.2914,\n",
      "         0.1984, -0.1531,  0.2852, -0.0600, -0.0061, -0.4860, -0.2413, -0.0346,\n",
      "        -0.5009, -0.0875,  0.2105,  0.2603,  0.1123,  0.1250, -0.1613,  0.3443,\n",
      "         0.3884,  0.6813,  0.1788, -0.1200,  0.4449,  0.4110, -0.0110, -0.3722,\n",
      "         0.2913, -0.5825,  0.0269, -0.1310, -0.1663,  0.1845,  0.0875,  0.2858,\n",
      "        -0.5931,  0.4339, -0.3135, -0.0496,  0.0170,  0.3280,  0.1517, -0.3754,\n",
      "         0.0563,  0.3316,  0.2202,  0.2046, -0.4855,  0.2711,  0.0478,  0.3011,\n",
      "         0.1946,  0.0052,  0.4864,  0.0085,  0.3529, -0.0217, -0.1446, -0.4572,\n",
      "         0.0402,  0.0112, -0.2950,  0.2482,  0.5013,  0.1227,  0.0681, -0.0057,\n",
      "         0.0380,  0.0350,  0.1517,  0.4596,  0.1600,  0.1147,  0.0255,  0.0105,\n",
      "        -0.0845, -0.4316, -0.6227,  0.5448,  0.1591, -0.4312,  0.2308,  0.1069,\n",
      "        -0.3868, -0.3427, -0.0683,  0.4948,  0.5426, -0.1749,  0.1567,  0.2879,\n",
      "        -0.2569, -0.4395,  0.2930, -0.3773, -0.3568,  0.3372,  0.0783, -0.2168,\n",
      "        -0.3699,  0.0858,  0.3274, -0.1538,  0.2111, -0.0371,  0.2232, -0.1146,\n",
      "         0.1960, -0.1865, -0.0398, -0.0103, -0.1860,  0.5114, -0.2270, -0.0243,\n",
      "         0.0067,  0.1663, -0.1077,  0.0399,  0.1274,  0.2116, -0.5604, -0.6647,\n",
      "        -0.0446,  0.0911,  0.2880,  0.1163, -0.0888, -0.0986,  0.4060, -0.0051,\n",
      "        -0.7805, -0.6864,  0.1119, -0.3648, -0.2971, -0.3174, -0.1211, -0.2591,\n",
      "        -0.2656, -0.5576,  0.3866, -0.4003, -0.0458,  0.5359,  0.1099,  0.4796,\n",
      "        -0.0355, -0.0887, -0.1493,  0.2110,  0.1812, -0.0970,  0.1416, -0.3561,\n",
      "         0.0958, -0.0053, -0.2814, -0.0881, -0.0179,  0.3206,  0.4799,  0.1066,\n",
      "        -0.1936, -0.4247,  0.0420,  0.1280, -0.3181,  0.0939, -0.1247,  0.2977,\n",
      "         0.2091,  0.1876,  0.2462,  0.1469,  0.1753, -0.0103,  0.0109, -0.2080,\n",
      "        -0.0742,  0.4644, -0.0287,  0.2367, -0.0960, -0.1824, -0.1848, -0.2896,\n",
      "         0.6602, -0.4105,  0.3902,  0.1416,  0.0629,  0.1451,  0.3968,  0.2589],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0098, -0.0533,  0.0536,  ..., -0.0844, -0.0657,  0.0011],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in params:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
