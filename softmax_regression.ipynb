{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T10:57:40.155307Z",
     "start_time": "2019-11-19T10:57:39.397309Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T10:57:40.164226Z",
     "start_time": "2019-11-19T10:57:40.157645Z"
    }
   },
   "outputs": [],
   "source": [
    "def use_svg_display():\n",
    "    # 用矢量图显示\n",
    "    display.set_matplotlib_formats('svg')\n",
    "\n",
    "def set_figsize(figsize=(3.5, 2.5)):\n",
    "    use_svg_display()\n",
    "    # 设置图的尺寸\n",
    "    plt.rcParams['figure.figsize'] = figsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T10:57:40.313608Z",
     "start_time": "2019-11-19T10:57:40.167465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris_test.csv     iris_training.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./data/iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T10:57:40.327551Z",
     "start_time": "2019-11-19T10:57:40.317143Z"
    }
   },
   "outputs": [],
   "source": [
    "class IrisDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, sep=','):\n",
    "        with open(csv_path, 'r') as f:\n",
    "            lines = f.readlines()[1:]\n",
    "            datas = [line.strip().split(sep) for line in lines]\n",
    "            datas_np = np.array(datas, dtype=np.float32)\n",
    "            self.featurs = torch.tensor(datas_np[:,:4], dtype=torch.float32)\n",
    "            self.labels = torch.tensor(datas_np[:,-1], dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.featurs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.featurs[index], self.labels[index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T10:57:40.349182Z",
     "start_time": "2019-11-19T10:57:40.335457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 30\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_csv_path = './data/iris/iris_training.csv'\n",
    "train_data_set = IrisDataSet(train_csv_path)\n",
    "train_data_iter = torch.utils.data.DataLoader(train_data_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_csv_path = './data/iris/iris_test.csv'\n",
    "test_data_set = IrisDataSet(test_csv_path)\n",
    "test_data_iter = torch.utils.data.DataLoader(test_data_set, batch_size=batch_size)\n",
    "\n",
    "print(len(train_data_set), len(test_data_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T10:56:12.415467Z",
     "start_time": "2019-11-19T10:56:12.404580Z"
    }
   },
   "source": [
    "### From scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T10:57:40.367562Z",
     "start_time": "2019-11-19T10:57:40.353375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0808, -0.5288, -0.1669],\n",
       "         [-1.3157, -0.0643, -1.2287],\n",
       "         [-0.5900,  2.5818, -0.8695],\n",
       "         [ 1.8603,  0.4940,  0.3751]], requires_grad=True),\n",
       " tensor([[0., 0., 0.]], requires_grad=True))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.randn((4,3), dtype=torch.float32)\n",
    "b = torch.zeros((1,3), dtype=torch.float32)\n",
    "\n",
    "w.requires_grad_(True)\n",
    "b.requires_grad_(True)\n",
    "\n",
    "w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T10:57:40.383511Z",
     "start_time": "2019-11-19T10:57:40.370380Z"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    x = x - x.max(dim=1, keepdim=True).values\n",
    "    return x.exp() / x.exp().sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T10:57:40.400904Z",
     "start_time": "2019-11-19T10:57:40.390582Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y, y_hat):\n",
    "    \"\"\"\n",
    "    y=[0,1,2]\n",
    "    y_hat = [\n",
    "        [0.7,0.2,0.1],\n",
    "        [0.2,0.5,0.3],\n",
    "        [0.1,0.1,0.8],\n",
    "    ]\n",
    "    \"\"\"\n",
    "    y_hat = softmax(y_hat)\n",
    "    return -torch.log(\n",
    "        y_hat.gather(dim=1, index=y.type(torch.long).view(-1,1))+1e-5\n",
    "    ).sum()\n",
    "\n",
    "def sgd(params, lr, bs):\n",
    "    for param in params:\n",
    "        param.data -= param.grad / bs * lr\n",
    "        \n",
    "def net(x):\n",
    "    return torch.mm(x, w) + b\n",
    "        \n",
    "def accuracy(y_hat, y):\n",
    "    return (y_hat.argmax(dim=1) == y).float().mean().item()\n",
    "\n",
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for X, y in data_iter:\n",
    "        acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T10:58:15.152103Z",
     "start_time": "2019-11-19T10:58:15.040449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss 0.5828 train_acc 0.7250 test_acc 0.8000\n",
      "epoch 2 loss 0.4597 train_acc 0.7667 test_acc 0.7333\n",
      "epoch 3 loss 0.4526 train_acc 0.8000 test_acc 0.7667\n",
      "epoch 4 loss 0.8481 train_acc 0.6250 test_acc 0.5333\n",
      "epoch 5 loss 0.6300 train_acc 0.6417 test_acc 0.5333\n",
      "epoch 6 loss 0.6672 train_acc 0.6667 test_acc 0.6333\n",
      "epoch 7 loss 0.4050 train_acc 0.7583 test_acc 0.6000\n",
      "epoch 8 loss 0.4357 train_acc 0.7667 test_acc 0.8333\n",
      "epoch 9 loss 0.4468 train_acc 0.7583 test_acc 0.5333\n",
      "epoch 10 loss 0.4980 train_acc 0.7500 test_acc 0.8667\n",
      "epoch 11 loss 0.4511 train_acc 0.7667 test_acc 0.9333\n",
      "epoch 12 loss 0.3844 train_acc 0.8167 test_acc 0.7000\n",
      "epoch 13 loss 0.3843 train_acc 0.8000 test_acc 0.5667\n",
      "epoch 14 loss 0.3886 train_acc 0.8000 test_acc 0.8000\n",
      "epoch 15 loss 0.3577 train_acc 0.8667 test_acc 0.8000\n",
      "epoch 16 loss 0.4792 train_acc 0.8083 test_acc 0.7333\n",
      "epoch 17 loss 0.5466 train_acc 0.6750 test_acc 0.6333\n",
      "epoch 18 loss 0.4900 train_acc 0.7333 test_acc 0.9333\n",
      "epoch 19 loss 0.3434 train_acc 0.9167 test_acc 0.9000\n",
      "epoch 20 loss 0.3453 train_acc 0.8667 test_acc 0.9333\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "num_epochs = 20\n",
    "params = [w, b]\n",
    "loss = cross_entropy_loss\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "    for x, y in train_data_iter:\n",
    "        for param in params:\n",
    "            if param.grad is not None:\n",
    "                param.grad.data.zero_()\n",
    "        y_hat = net(x)\n",
    "        l = cross_entropy_loss(y, y_hat)\n",
    "        l.backward()\n",
    "        sgd(params, lr, batch_size)\n",
    "        \n",
    "        train_l_sum += l.item()\n",
    "        train_acc_sum += (y_hat.argmax(dim=1)==y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    print('epoch %d loss %.4f train_acc %.4f test_acc %.4f' %\n",
    "          (epoch, train_l_sum/n, train_acc_sum/n, evaluate_accuracy(test_data_iter, net)))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T10:56:34.844438Z",
     "start_time": "2019-11-19T10:56:34.841435Z"
    }
   },
   "source": [
    "### By torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T11:46:36.039625Z",
     "start_time": "2019-11-19T11:46:36.035149Z"
    }
   },
   "outputs": [],
   "source": [
    "class LinearNet(torch.nn.Module):\n",
    "    def __init__(self, input, output):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(input, output)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T11:51:03.999122Z",
     "start_time": "2019-11-19T11:51:03.986863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 3e-4\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "net = LinearNet(4, 3)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "torch.nn.init.normal_(net.linear.weight, 0., 0.1)\n",
    "torch.nn.init.constant_(net.linear.bias, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T11:51:04.666636Z",
     "start_time": "2019-11-19T11:51:04.659891Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, batch_size, net, loss, train_data_iter, test_data_iter, optimizer):\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0\n",
    "        for x, y in train_data_iter:\n",
    "            for param in params:\n",
    "                if param.grad is not None:\n",
    "                    param.grad.data.zero_()\n",
    "            y_hat = net(x)\n",
    "            l = cross_entropy_loss(y, y_hat)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_l_sum += l.item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1)==y).float().sum().item()\n",
    "            n += y.shape[0]\n",
    "        print('epoch %d loss %.4f train_acc %.4f test_acc %.4f' %\n",
    "              (epoch, train_l_sum/n, train_acc_sum/n, evaluate_accuracy(test_data_iter, net)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T11:51:22.325361Z",
     "start_time": "2019-11-19T11:51:15.846037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss 0.6342 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 2 loss 0.6423 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 3 loss 0.6468 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 4 loss 0.6473 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 5 loss 0.6437 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 6 loss 0.6351 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 7 loss 0.6235 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 8 loss 0.6056 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 9 loss 0.5863 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 10 loss 0.5628 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 11 loss 0.5394 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 12 loss 0.5154 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 13 loss 0.4926 train_acc 0.6583 test_acc 0.7333\n",
      "epoch 14 loss 0.4778 train_acc 0.7833 test_acc 0.9333\n",
      "epoch 15 loss 0.4600 train_acc 0.9500 test_acc 0.9333\n",
      "epoch 16 loss 0.4529 train_acc 0.9167 test_acc 0.6333\n",
      "epoch 17 loss 0.4494 train_acc 0.7417 test_acc 0.5667\n",
      "epoch 18 loss 0.4517 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 19 loss 0.4589 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 20 loss 0.4749 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 21 loss 0.4937 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 22 loss 0.5154 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 23 loss 0.5371 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 24 loss 0.5583 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 25 loss 0.5849 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 26 loss 0.6090 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 27 loss 0.6285 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 28 loss 0.6502 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 29 loss 0.6682 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 30 loss 0.6814 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 31 loss 0.6914 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 32 loss 0.6978 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 33 loss 0.7000 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 34 loss 0.6979 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 35 loss 0.6915 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 36 loss 0.6808 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 37 loss 0.6660 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 38 loss 0.6487 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 39 loss 0.6244 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 40 loss 0.6036 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 41 loss 0.5783 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 42 loss 0.5500 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 43 loss 0.5233 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 44 loss 0.4961 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 45 loss 0.4730 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 46 loss 0.4516 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 47 loss 0.4308 train_acc 0.7083 test_acc 0.5667\n",
      "epoch 48 loss 0.4162 train_acc 0.7167 test_acc 0.6000\n",
      "epoch 49 loss 0.4060 train_acc 0.7917 test_acc 0.7667\n",
      "epoch 50 loss 0.4022 train_acc 0.8833 test_acc 0.9333\n",
      "epoch 51 loss 0.4065 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 52 loss 0.4144 train_acc 0.9417 test_acc 0.9333\n",
      "epoch 53 loss 0.4302 train_acc 0.7917 test_acc 0.7667\n",
      "epoch 54 loss 0.4524 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 55 loss 0.4772 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 56 loss 0.5030 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 57 loss 0.5309 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 58 loss 0.5608 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 59 loss 0.5867 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 60 loss 0.6169 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 61 loss 0.6410 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 62 loss 0.6615 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 63 loss 0.6796 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 64 loss 0.6915 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 65 loss 0.6998 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 66 loss 0.7022 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 67 loss 0.6993 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 68 loss 0.6912 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 69 loss 0.6780 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 70 loss 0.6593 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 71 loss 0.6364 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 72 loss 0.6107 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 73 loss 0.5790 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 74 loss 0.5480 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 75 loss 0.5169 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 76 loss 0.4825 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 77 loss 0.4493 train_acc 0.6583 test_acc 0.7333\n",
      "epoch 78 loss 0.4189 train_acc 0.7000 test_acc 0.7667\n",
      "epoch 79 loss 0.3919 train_acc 0.7667 test_acc 0.9333\n",
      "epoch 80 loss 0.3755 train_acc 0.8750 test_acc 0.9667\n",
      "epoch 81 loss 0.3622 train_acc 0.9500 test_acc 1.0000\n",
      "epoch 82 loss 0.3511 train_acc 0.9667 test_acc 0.9000\n",
      "epoch 83 loss 0.3520 train_acc 0.9000 test_acc 0.7333\n",
      "epoch 84 loss 0.3580 train_acc 0.8250 test_acc 0.6333\n",
      "epoch 85 loss 0.3670 train_acc 0.7667 test_acc 0.5667\n",
      "epoch 86 loss 0.3890 train_acc 0.7250 test_acc 0.5667\n",
      "epoch 87 loss 0.4066 train_acc 0.7083 test_acc 0.5333\n",
      "epoch 88 loss 0.4334 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 89 loss 0.4623 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 90 loss 0.4903 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 91 loss 0.5244 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 92 loss 0.5586 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 93 loss 0.5852 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 94 loss 0.6160 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 95 loss 0.6420 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 96 loss 0.6682 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 97 loss 0.6925 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 98 loss 0.7171 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 99 loss 0.7324 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 100 loss 0.7501 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 101 loss 0.7621 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 102 loss 0.7729 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 103 loss 0.7793 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 104 loss 0.7829 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 105 loss 0.7830 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 106 loss 0.7800 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 107 loss 0.7733 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 108 loss 0.7639 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 109 loss 0.7509 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 110 loss 0.7364 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 111 loss 0.7161 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 112 loss 0.6935 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 113 loss 0.6693 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 114 loss 0.6443 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 115 loss 0.6139 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 116 loss 0.5867 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 117 loss 0.5568 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 118 loss 0.5227 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 119 loss 0.4924 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 120 loss 0.4592 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 121 loss 0.4293 train_acc 0.7000 test_acc 0.5667\n",
      "epoch 122 loss 0.4033 train_acc 0.7083 test_acc 0.5667\n",
      "epoch 123 loss 0.3771 train_acc 0.7417 test_acc 0.6333\n",
      "epoch 124 loss 0.3547 train_acc 0.7750 test_acc 0.6667\n",
      "epoch 125 loss 0.3391 train_acc 0.8250 test_acc 0.7667\n",
      "epoch 126 loss 0.3251 train_acc 0.8833 test_acc 0.9000\n",
      "epoch 127 loss 0.3144 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 128 loss 0.3135 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 129 loss 0.3161 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 130 loss 0.3233 train_acc 0.9417 test_acc 0.9667\n",
      "epoch 131 loss 0.3367 train_acc 0.8667 test_acc 0.8667\n",
      "epoch 132 loss 0.3587 train_acc 0.8083 test_acc 0.8000\n",
      "epoch 133 loss 0.3806 train_acc 0.7500 test_acc 0.7667\n",
      "epoch 134 loss 0.4094 train_acc 0.6917 test_acc 0.7333\n",
      "epoch 135 loss 0.4378 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 136 loss 0.4699 train_acc 0.6583 test_acc 0.7333\n",
      "epoch 137 loss 0.5047 train_acc 0.6583 test_acc 0.7333\n",
      "epoch 138 loss 0.5377 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 139 loss 0.5692 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 140 loss 0.6027 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 141 loss 0.6368 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 142 loss 0.6642 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 143 loss 0.6906 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 144 loss 0.7103 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 145 loss 0.7308 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 146 loss 0.7454 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 147 loss 0.7568 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 148 loss 0.7636 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 149 loss 0.7661 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 150 loss 0.7643 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 151 loss 0.7580 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 152 loss 0.7471 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 153 loss 0.7321 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 154 loss 0.7138 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 155 loss 0.6908 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 156 loss 0.6639 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 157 loss 0.6314 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 158 loss 0.6010 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 159 loss 0.5673 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 160 loss 0.5294 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 161 loss 0.4908 train_acc 0.6583 test_acc 0.7333\n",
      "epoch 162 loss 0.4558 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 163 loss 0.4208 train_acc 0.6750 test_acc 0.7667\n",
      "epoch 164 loss 0.3796 train_acc 0.7333 test_acc 0.8000\n",
      "epoch 165 loss 0.3501 train_acc 0.7667 test_acc 0.8667\n",
      "epoch 166 loss 0.3202 train_acc 0.8250 test_acc 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 167 loss 0.2978 train_acc 0.8833 test_acc 0.9667\n",
      "epoch 168 loss 0.2762 train_acc 0.9250 test_acc 0.9667\n",
      "epoch 169 loss 0.2605 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 170 loss 0.2564 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 171 loss 0.2534 train_acc 0.9667 test_acc 0.9333\n",
      "epoch 172 loss 0.2576 train_acc 0.9500 test_acc 0.9000\n",
      "epoch 173 loss 0.2645 train_acc 0.9167 test_acc 0.7667\n",
      "epoch 174 loss 0.2816 train_acc 0.8500 test_acc 0.7000\n",
      "epoch 175 loss 0.2994 train_acc 0.8167 test_acc 0.6333\n",
      "epoch 176 loss 0.3202 train_acc 0.7917 test_acc 0.6000\n",
      "epoch 177 loss 0.3488 train_acc 0.7750 test_acc 0.6000\n",
      "epoch 178 loss 0.3744 train_acc 0.7333 test_acc 0.5667\n",
      "epoch 179 loss 0.4058 train_acc 0.7167 test_acc 0.5667\n",
      "epoch 180 loss 0.4371 train_acc 0.7083 test_acc 0.5667\n",
      "epoch 181 loss 0.4708 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 182 loss 0.5049 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 183 loss 0.5340 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 184 loss 0.5662 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 185 loss 0.5987 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 186 loss 0.6251 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 187 loss 0.6553 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 188 loss 0.6804 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 189 loss 0.7058 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 190 loss 0.7277 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 191 loss 0.7483 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 192 loss 0.7675 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 193 loss 0.7824 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 194 loss 0.7959 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 195 loss 0.8082 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 196 loss 0.8168 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 197 loss 0.8230 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 198 loss 0.8267 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 199 loss 0.8277 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 200 loss 0.8265 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 201 loss 0.8222 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 202 loss 0.8154 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 203 loss 0.8066 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 204 loss 0.7948 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 205 loss 0.7801 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 206 loss 0.7647 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 207 loss 0.7454 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 208 loss 0.7249 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 209 loss 0.7020 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 210 loss 0.6760 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 211 loss 0.6506 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 212 loss 0.6209 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 213 loss 0.5914 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 214 loss 0.5605 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 215 loss 0.5275 train_acc 0.7000 test_acc 0.5667\n",
      "epoch 216 loss 0.4969 train_acc 0.7083 test_acc 0.5667\n",
      "epoch 217 loss 0.4646 train_acc 0.7167 test_acc 0.5667\n",
      "epoch 218 loss 0.4326 train_acc 0.7250 test_acc 0.5667\n",
      "epoch 219 loss 0.3995 train_acc 0.7333 test_acc 0.6000\n",
      "epoch 220 loss 0.3686 train_acc 0.7417 test_acc 0.6000\n",
      "epoch 221 loss 0.3455 train_acc 0.7750 test_acc 0.6333\n",
      "epoch 222 loss 0.3158 train_acc 0.7917 test_acc 0.7000\n",
      "epoch 223 loss 0.2906 train_acc 0.8250 test_acc 0.7333\n",
      "epoch 224 loss 0.2685 train_acc 0.8500 test_acc 0.7667\n",
      "epoch 225 loss 0.2539 train_acc 0.8917 test_acc 0.9000\n",
      "epoch 226 loss 0.2357 train_acc 0.9250 test_acc 0.9000\n",
      "epoch 227 loss 0.2266 train_acc 0.9500 test_acc 0.9333\n",
      "epoch 228 loss 0.2182 train_acc 0.9667 test_acc 0.9667\n",
      "epoch 229 loss 0.2166 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 230 loss 0.2190 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 231 loss 0.2265 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 232 loss 0.2367 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 233 loss 0.2533 train_acc 0.9250 test_acc 0.9667\n",
      "epoch 234 loss 0.2737 train_acc 0.8917 test_acc 0.9333\n",
      "epoch 235 loss 0.2977 train_acc 0.8500 test_acc 0.9000\n",
      "epoch 236 loss 0.3219 train_acc 0.8417 test_acc 0.8333\n",
      "epoch 237 loss 0.3537 train_acc 0.7917 test_acc 0.8333\n",
      "epoch 238 loss 0.3851 train_acc 0.7583 test_acc 0.8000\n",
      "epoch 239 loss 0.4199 train_acc 0.7417 test_acc 0.7667\n",
      "epoch 240 loss 0.4536 train_acc 0.7083 test_acc 0.7667\n",
      "epoch 241 loss 0.4875 train_acc 0.6833 test_acc 0.7667\n",
      "epoch 242 loss 0.5230 train_acc 0.6833 test_acc 0.7333\n",
      "epoch 243 loss 0.5609 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 244 loss 0.5933 train_acc 0.6583 test_acc 0.7333\n",
      "epoch 245 loss 0.6242 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 246 loss 0.6531 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 247 loss 0.6825 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 248 loss 0.7080 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 249 loss 0.7301 train_acc 0.6417 test_acc 0.7333\n",
      "epoch 250 loss 0.7484 train_acc 0.6417 test_acc 0.7333\n",
      "epoch 251 loss 0.7644 train_acc 0.6417 test_acc 0.7333\n",
      "epoch 252 loss 0.7768 train_acc 0.6417 test_acc 0.7333\n",
      "epoch 253 loss 0.7858 train_acc 0.6417 test_acc 0.7333\n",
      "epoch 254 loss 0.7911 train_acc 0.6417 test_acc 0.7333\n",
      "epoch 255 loss 0.7925 train_acc 0.6417 test_acc 0.7333\n",
      "epoch 256 loss 0.7902 train_acc 0.6417 test_acc 0.7333\n",
      "epoch 257 loss 0.7842 train_acc 0.6417 test_acc 0.7333\n",
      "epoch 258 loss 0.7749 train_acc 0.6417 test_acc 0.7333\n",
      "epoch 259 loss 0.7612 train_acc 0.6417 test_acc 0.7333\n",
      "epoch 260 loss 0.7443 train_acc 0.6417 test_acc 0.7333\n",
      "epoch 261 loss 0.7243 train_acc 0.6500 test_acc 0.7333\n",
      "epoch 262 loss 0.7028 train_acc 0.6583 test_acc 0.7333\n",
      "epoch 263 loss 0.6756 train_acc 0.6583 test_acc 0.7333\n",
      "epoch 264 loss 0.6479 train_acc 0.6667 test_acc 0.7333\n",
      "epoch 265 loss 0.6174 train_acc 0.6667 test_acc 0.7333\n",
      "epoch 266 loss 0.5839 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 267 loss 0.5481 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 268 loss 0.5113 train_acc 0.6833 test_acc 0.7667\n",
      "epoch 269 loss 0.4776 train_acc 0.6833 test_acc 0.7667\n",
      "epoch 270 loss 0.4395 train_acc 0.7250 test_acc 0.8000\n",
      "epoch 271 loss 0.4053 train_acc 0.7417 test_acc 0.8000\n",
      "epoch 272 loss 0.3707 train_acc 0.7583 test_acc 0.8333\n",
      "epoch 273 loss 0.3381 train_acc 0.7833 test_acc 0.8667\n",
      "epoch 274 loss 0.3045 train_acc 0.8250 test_acc 0.9000\n",
      "epoch 275 loss 0.2751 train_acc 0.8500 test_acc 0.9333\n",
      "epoch 276 loss 0.2511 train_acc 0.8750 test_acc 0.9667\n",
      "epoch 277 loss 0.2293 train_acc 0.9167 test_acc 0.9667\n",
      "epoch 278 loss 0.2112 train_acc 0.9250 test_acc 0.9667\n",
      "epoch 279 loss 0.1961 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 280 loss 0.1844 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 281 loss 0.1781 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 282 loss 0.1746 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 283 loss 0.1752 train_acc 0.9667 test_acc 0.9333\n",
      "epoch 284 loss 0.1803 train_acc 0.9667 test_acc 0.9333\n",
      "epoch 285 loss 0.1881 train_acc 0.9583 test_acc 0.9000\n",
      "epoch 286 loss 0.1992 train_acc 0.9333 test_acc 0.9000\n",
      "epoch 287 loss 0.2158 train_acc 0.9083 test_acc 0.8333\n",
      "epoch 288 loss 0.2304 train_acc 0.8833 test_acc 0.7667\n",
      "epoch 289 loss 0.2514 train_acc 0.8500 test_acc 0.7333\n",
      "epoch 290 loss 0.2731 train_acc 0.8417 test_acc 0.7000\n",
      "epoch 291 loss 0.2953 train_acc 0.8250 test_acc 0.6667\n",
      "epoch 292 loss 0.3210 train_acc 0.8000 test_acc 0.6667\n",
      "epoch 293 loss 0.3459 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 294 loss 0.3733 train_acc 0.7750 test_acc 0.6000\n",
      "epoch 295 loss 0.4016 train_acc 0.7583 test_acc 0.6000\n",
      "epoch 296 loss 0.4288 train_acc 0.7417 test_acc 0.6000\n",
      "epoch 297 loss 0.4566 train_acc 0.7417 test_acc 0.5667\n",
      "epoch 298 loss 0.4840 train_acc 0.7333 test_acc 0.5667\n",
      "epoch 299 loss 0.5102 train_acc 0.7250 test_acc 0.5667\n",
      "epoch 300 loss 0.5387 train_acc 0.7167 test_acc 0.5667\n",
      "epoch 301 loss 0.5638 train_acc 0.7083 test_acc 0.5667\n",
      "epoch 302 loss 0.5894 train_acc 0.7083 test_acc 0.5667\n",
      "epoch 303 loss 0.6140 train_acc 0.7083 test_acc 0.5667\n",
      "epoch 304 loss 0.6369 train_acc 0.7083 test_acc 0.5667\n",
      "epoch 305 loss 0.6603 train_acc 0.7083 test_acc 0.5333\n",
      "epoch 306 loss 0.6809 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 307 loss 0.7003 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 308 loss 0.7164 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 309 loss 0.7329 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 310 loss 0.7476 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 311 loss 0.7604 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 312 loss 0.7715 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 313 loss 0.7798 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 314 loss 0.7880 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 315 loss 0.7933 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 316 loss 0.7974 train_acc 0.7000 test_acc 0.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 317 loss 0.7994 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 318 loss 0.7996 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 319 loss 0.7978 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 320 loss 0.7946 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 321 loss 0.7894 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 322 loss 0.7821 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 323 loss 0.7730 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 324 loss 0.7631 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 325 loss 0.7509 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 326 loss 0.7367 train_acc 0.7000 test_acc 0.5333\n",
      "epoch 327 loss 0.7205 train_acc 0.7000 test_acc 0.5667\n",
      "epoch 328 loss 0.7049 train_acc 0.7000 test_acc 0.5667\n",
      "epoch 329 loss 0.6845 train_acc 0.7000 test_acc 0.5667\n",
      "epoch 330 loss 0.6651 train_acc 0.7000 test_acc 0.5667\n",
      "epoch 331 loss 0.6438 train_acc 0.7000 test_acc 0.5667\n",
      "epoch 332 loss 0.6202 train_acc 0.7000 test_acc 0.5667\n",
      "epoch 333 loss 0.5993 train_acc 0.7000 test_acc 0.5667\n",
      "epoch 334 loss 0.5738 train_acc 0.7167 test_acc 0.5667\n",
      "epoch 335 loss 0.5486 train_acc 0.7167 test_acc 0.5667\n",
      "epoch 336 loss 0.5249 train_acc 0.7250 test_acc 0.6000\n",
      "epoch 337 loss 0.4967 train_acc 0.7333 test_acc 0.6000\n",
      "epoch 338 loss 0.4689 train_acc 0.7333 test_acc 0.6000\n",
      "epoch 339 loss 0.4419 train_acc 0.7417 test_acc 0.6333\n",
      "epoch 340 loss 0.4156 train_acc 0.7583 test_acc 0.6333\n",
      "epoch 341 loss 0.3898 train_acc 0.7833 test_acc 0.6667\n",
      "epoch 342 loss 0.3622 train_acc 0.7833 test_acc 0.6667\n",
      "epoch 343 loss 0.3365 train_acc 0.8083 test_acc 0.7000\n",
      "epoch 344 loss 0.3132 train_acc 0.8250 test_acc 0.7333\n",
      "epoch 345 loss 0.2885 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 346 loss 0.2678 train_acc 0.8500 test_acc 0.7667\n",
      "epoch 347 loss 0.2468 train_acc 0.8833 test_acc 0.8667\n",
      "epoch 348 loss 0.2272 train_acc 0.9000 test_acc 0.9000\n",
      "epoch 349 loss 0.2094 train_acc 0.9333 test_acc 0.9000\n",
      "epoch 350 loss 0.1956 train_acc 0.9417 test_acc 0.9333\n",
      "epoch 351 loss 0.1807 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 352 loss 0.1698 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 353 loss 0.1614 train_acc 0.9667 test_acc 0.9667\n",
      "epoch 354 loss 0.1551 train_acc 0.9750 test_acc 1.0000\n",
      "epoch 355 loss 0.1507 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 356 loss 0.1518 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 357 loss 0.1527 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 358 loss 0.1579 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 359 loss 0.1635 train_acc 0.9667 test_acc 0.9667\n",
      "epoch 360 loss 0.1753 train_acc 0.9333 test_acc 0.9667\n",
      "epoch 361 loss 0.1855 train_acc 0.9250 test_acc 0.9667\n",
      "epoch 362 loss 0.1993 train_acc 0.9167 test_acc 0.9667\n",
      "epoch 363 loss 0.2194 train_acc 0.8833 test_acc 0.9333\n",
      "epoch 364 loss 0.2380 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 365 loss 0.2598 train_acc 0.8417 test_acc 0.9000\n",
      "epoch 366 loss 0.2837 train_acc 0.8417 test_acc 0.9000\n",
      "epoch 367 loss 0.3058 train_acc 0.8333 test_acc 0.8333\n",
      "epoch 368 loss 0.3342 train_acc 0.8083 test_acc 0.8333\n",
      "epoch 369 loss 0.3587 train_acc 0.7750 test_acc 0.8333\n",
      "epoch 370 loss 0.3866 train_acc 0.7583 test_acc 0.8000\n",
      "epoch 371 loss 0.4170 train_acc 0.7500 test_acc 0.8000\n",
      "epoch 372 loss 0.4445 train_acc 0.7417 test_acc 0.8000\n",
      "epoch 373 loss 0.4719 train_acc 0.7333 test_acc 0.7667\n",
      "epoch 374 loss 0.5003 train_acc 0.7083 test_acc 0.7667\n",
      "epoch 375 loss 0.5263 train_acc 0.7083 test_acc 0.7667\n",
      "epoch 376 loss 0.5545 train_acc 0.7000 test_acc 0.7667\n",
      "epoch 377 loss 0.5792 train_acc 0.6833 test_acc 0.7667\n",
      "epoch 378 loss 0.6020 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 379 loss 0.6240 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 380 loss 0.6442 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 381 loss 0.6642 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 382 loss 0.6823 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 383 loss 0.6972 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 384 loss 0.7097 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 385 loss 0.7194 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 386 loss 0.7288 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 387 loss 0.7345 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 388 loss 0.7384 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 389 loss 0.7397 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 390 loss 0.7387 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 391 loss 0.7352 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 392 loss 0.7295 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 393 loss 0.7209 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 394 loss 0.7107 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 395 loss 0.6985 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 396 loss 0.6830 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 397 loss 0.6661 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 398 loss 0.6467 train_acc 0.6750 test_acc 0.7333\n",
      "epoch 399 loss 0.6259 train_acc 0.6833 test_acc 0.7667\n",
      "epoch 400 loss 0.6038 train_acc 0.6833 test_acc 0.7667\n",
      "epoch 401 loss 0.5791 train_acc 0.6833 test_acc 0.7667\n",
      "epoch 402 loss 0.5522 train_acc 0.7083 test_acc 0.7667\n",
      "epoch 403 loss 0.5296 train_acc 0.7167 test_acc 0.8000\n",
      "epoch 404 loss 0.5005 train_acc 0.7250 test_acc 0.8000\n",
      "epoch 405 loss 0.4726 train_acc 0.7417 test_acc 0.8000\n",
      "epoch 406 loss 0.4443 train_acc 0.7417 test_acc 0.8000\n",
      "epoch 407 loss 0.4138 train_acc 0.7667 test_acc 0.8333\n",
      "epoch 408 loss 0.3848 train_acc 0.7750 test_acc 0.8333\n",
      "epoch 409 loss 0.3579 train_acc 0.7750 test_acc 0.8333\n",
      "epoch 410 loss 0.3324 train_acc 0.8083 test_acc 0.8667\n",
      "epoch 411 loss 0.3042 train_acc 0.8333 test_acc 0.9000\n",
      "epoch 412 loss 0.2769 train_acc 0.8417 test_acc 0.9333\n",
      "epoch 413 loss 0.2545 train_acc 0.8500 test_acc 0.9333\n",
      "epoch 414 loss 0.2334 train_acc 0.8833 test_acc 0.9333\n",
      "epoch 415 loss 0.2077 train_acc 0.9000 test_acc 0.9667\n",
      "epoch 416 loss 0.1917 train_acc 0.9167 test_acc 0.9667\n",
      "epoch 417 loss 0.1740 train_acc 0.9167 test_acc 0.9667\n",
      "epoch 418 loss 0.1614 train_acc 0.9333 test_acc 0.9667\n",
      "epoch 419 loss 0.1486 train_acc 0.9500 test_acc 0.9667\n",
      "epoch 420 loss 0.1396 train_acc 0.9667 test_acc 0.9667\n",
      "epoch 421 loss 0.1324 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 422 loss 0.1272 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 423 loss 0.1226 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 424 loss 0.1231 train_acc 0.9833 test_acc 1.0000\n",
      "epoch 425 loss 0.1251 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 426 loss 0.1283 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 427 loss 0.1330 train_acc 0.9667 test_acc 0.9333\n",
      "epoch 428 loss 0.1395 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 429 loss 0.1491 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 430 loss 0.1580 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 431 loss 0.1709 train_acc 0.9500 test_acc 0.9000\n",
      "epoch 432 loss 0.1839 train_acc 0.9333 test_acc 0.9000\n",
      "epoch 433 loss 0.1982 train_acc 0.9167 test_acc 0.9000\n",
      "epoch 434 loss 0.2139 train_acc 0.9000 test_acc 0.8667\n",
      "epoch 435 loss 0.2307 train_acc 0.8917 test_acc 0.8000\n",
      "epoch 436 loss 0.2471 train_acc 0.8833 test_acc 0.7333\n",
      "epoch 437 loss 0.2663 train_acc 0.8500 test_acc 0.7333\n",
      "epoch 438 loss 0.2872 train_acc 0.8500 test_acc 0.7333\n",
      "epoch 439 loss 0.3059 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 440 loss 0.3252 train_acc 0.8417 test_acc 0.7000\n",
      "epoch 441 loss 0.3482 train_acc 0.8250 test_acc 0.7000\n",
      "epoch 442 loss 0.3653 train_acc 0.8167 test_acc 0.6667\n",
      "epoch 443 loss 0.3875 train_acc 0.8000 test_acc 0.6667\n",
      "epoch 444 loss 0.4087 train_acc 0.7917 test_acc 0.6667\n",
      "epoch 445 loss 0.4299 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 446 loss 0.4508 train_acc 0.7750 test_acc 0.6333\n",
      "epoch 447 loss 0.4723 train_acc 0.7750 test_acc 0.6333\n",
      "epoch 448 loss 0.4926 train_acc 0.7667 test_acc 0.6333\n",
      "epoch 449 loss 0.5116 train_acc 0.7583 test_acc 0.6000\n",
      "epoch 450 loss 0.5294 train_acc 0.7500 test_acc 0.6000\n",
      "epoch 451 loss 0.5483 train_acc 0.7417 test_acc 0.6000\n",
      "epoch 452 loss 0.5654 train_acc 0.7417 test_acc 0.6000\n",
      "epoch 453 loss 0.5825 train_acc 0.7333 test_acc 0.6000\n",
      "epoch 454 loss 0.5984 train_acc 0.7333 test_acc 0.6000\n",
      "epoch 455 loss 0.6140 train_acc 0.7250 test_acc 0.5667\n",
      "epoch 456 loss 0.6279 train_acc 0.7250 test_acc 0.5667\n",
      "epoch 457 loss 0.6394 train_acc 0.7250 test_acc 0.5667\n",
      "epoch 458 loss 0.6526 train_acc 0.7250 test_acc 0.5667\n",
      "epoch 459 loss 0.6620 train_acc 0.7250 test_acc 0.5667\n",
      "epoch 460 loss 0.6717 train_acc 0.7250 test_acc 0.5667\n",
      "epoch 461 loss 0.6800 train_acc 0.7250 test_acc 0.5667\n",
      "epoch 462 loss 0.6868 train_acc 0.7250 test_acc 0.5667\n",
      "epoch 463 loss 0.6929 train_acc 0.7250 test_acc 0.5667\n",
      "epoch 464 loss 0.6976 train_acc 0.7250 test_acc 0.5667\n",
      "epoch 465 loss 0.7005 train_acc 0.7250 test_acc 0.5667\n",
      "epoch 466 loss 0.7025 train_acc 0.7167 test_acc 0.5667\n",
      "epoch 467 loss 0.7033 train_acc 0.7167 test_acc 0.5667\n",
      "epoch 468 loss 0.7027 train_acc 0.7167 test_acc 0.5667\n",
      "epoch 469 loss 0.7007 train_acc 0.7250 test_acc 0.5667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 470 loss 0.6976 train_acc 0.7250 test_acc 0.5667\n",
      "epoch 471 loss 0.6932 train_acc 0.7250 test_acc 0.5667\n",
      "epoch 472 loss 0.6874 train_acc 0.7333 test_acc 0.5667\n",
      "epoch 473 loss 0.6804 train_acc 0.7333 test_acc 0.5667\n",
      "epoch 474 loss 0.6723 train_acc 0.7333 test_acc 0.5667\n",
      "epoch 475 loss 0.6627 train_acc 0.7333 test_acc 0.5667\n",
      "epoch 476 loss 0.6532 train_acc 0.7333 test_acc 0.5667\n",
      "epoch 477 loss 0.6417 train_acc 0.7333 test_acc 0.5667\n",
      "epoch 478 loss 0.6276 train_acc 0.7333 test_acc 0.6000\n",
      "epoch 479 loss 0.6140 train_acc 0.7417 test_acc 0.6000\n",
      "epoch 480 loss 0.5990 train_acc 0.7417 test_acc 0.6000\n",
      "epoch 481 loss 0.5833 train_acc 0.7500 test_acc 0.6000\n",
      "epoch 482 loss 0.5661 train_acc 0.7500 test_acc 0.6000\n",
      "epoch 483 loss 0.5502 train_acc 0.7500 test_acc 0.6000\n",
      "epoch 484 loss 0.5308 train_acc 0.7583 test_acc 0.6333\n",
      "epoch 485 loss 0.5112 train_acc 0.7667 test_acc 0.6333\n",
      "epoch 486 loss 0.4936 train_acc 0.7750 test_acc 0.6333\n",
      "epoch 487 loss 0.4706 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 488 loss 0.4525 train_acc 0.7833 test_acc 0.6667\n",
      "epoch 489 loss 0.4309 train_acc 0.7917 test_acc 0.6667\n",
      "epoch 490 loss 0.4108 train_acc 0.8000 test_acc 0.6667\n",
      "epoch 491 loss 0.3891 train_acc 0.8167 test_acc 0.7000\n",
      "epoch 492 loss 0.3686 train_acc 0.8250 test_acc 0.7000\n",
      "epoch 493 loss 0.3471 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 494 loss 0.3294 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 495 loss 0.3082 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 496 loss 0.2902 train_acc 0.8500 test_acc 0.7333\n",
      "epoch 497 loss 0.2698 train_acc 0.8500 test_acc 0.7333\n",
      "epoch 498 loss 0.2509 train_acc 0.8667 test_acc 0.7667\n",
      "epoch 499 loss 0.2325 train_acc 0.8833 test_acc 0.8333\n",
      "epoch 500 loss 0.2184 train_acc 0.8917 test_acc 0.8667\n",
      "epoch 501 loss 0.2009 train_acc 0.9000 test_acc 0.9000\n",
      "epoch 502 loss 0.1857 train_acc 0.9167 test_acc 0.9000\n",
      "epoch 503 loss 0.1738 train_acc 0.9333 test_acc 0.9333\n",
      "epoch 504 loss 0.1605 train_acc 0.9333 test_acc 0.9333\n",
      "epoch 505 loss 0.1479 train_acc 0.9500 test_acc 0.9333\n",
      "epoch 506 loss 0.1383 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 507 loss 0.1288 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 508 loss 0.1195 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 509 loss 0.1137 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 510 loss 0.1067 train_acc 0.9667 test_acc 0.9667\n",
      "epoch 511 loss 0.1034 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 512 loss 0.0988 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 513 loss 0.0966 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 514 loss 0.0977 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 515 loss 0.0972 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 516 loss 0.0998 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 517 loss 0.1019 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 518 loss 0.1067 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 519 loss 0.1128 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 520 loss 0.1200 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 521 loss 0.1288 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 522 loss 0.1377 train_acc 0.9417 test_acc 0.9667\n",
      "epoch 523 loss 0.1480 train_acc 0.9250 test_acc 0.9667\n",
      "epoch 524 loss 0.1622 train_acc 0.9167 test_acc 0.9667\n",
      "epoch 525 loss 0.1748 train_acc 0.9167 test_acc 0.9667\n",
      "epoch 526 loss 0.1901 train_acc 0.9083 test_acc 0.9667\n",
      "epoch 527 loss 0.2058 train_acc 0.8917 test_acc 0.9333\n",
      "epoch 528 loss 0.2208 train_acc 0.8833 test_acc 0.9333\n",
      "epoch 529 loss 0.2405 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 530 loss 0.2590 train_acc 0.8583 test_acc 0.9333\n",
      "epoch 531 loss 0.2761 train_acc 0.8500 test_acc 0.9333\n",
      "epoch 532 loss 0.2957 train_acc 0.8417 test_acc 0.9000\n",
      "epoch 533 loss 0.3172 train_acc 0.8333 test_acc 0.9000\n",
      "epoch 534 loss 0.3386 train_acc 0.8333 test_acc 0.9000\n",
      "epoch 535 loss 0.3575 train_acc 0.8250 test_acc 0.9000\n",
      "epoch 536 loss 0.3774 train_acc 0.8083 test_acc 0.8333\n",
      "epoch 537 loss 0.3975 train_acc 0.8000 test_acc 0.8333\n",
      "epoch 538 loss 0.4192 train_acc 0.7917 test_acc 0.8333\n",
      "epoch 539 loss 0.4395 train_acc 0.7750 test_acc 0.8333\n",
      "epoch 540 loss 0.4581 train_acc 0.7667 test_acc 0.8333\n",
      "epoch 541 loss 0.4783 train_acc 0.7667 test_acc 0.8333\n",
      "epoch 542 loss 0.4958 train_acc 0.7583 test_acc 0.8000\n",
      "epoch 543 loss 0.5135 train_acc 0.7417 test_acc 0.8000\n",
      "epoch 544 loss 0.5307 train_acc 0.7417 test_acc 0.8000\n",
      "epoch 545 loss 0.5450 train_acc 0.7333 test_acc 0.8000\n",
      "epoch 546 loss 0.5598 train_acc 0.7333 test_acc 0.8000\n",
      "epoch 547 loss 0.5732 train_acc 0.7333 test_acc 0.8000\n",
      "epoch 548 loss 0.5853 train_acc 0.7333 test_acc 0.8000\n",
      "epoch 549 loss 0.5957 train_acc 0.7333 test_acc 0.8000\n",
      "epoch 550 loss 0.6048 train_acc 0.7333 test_acc 0.8000\n",
      "epoch 551 loss 0.6130 train_acc 0.7250 test_acc 0.8000\n",
      "epoch 552 loss 0.6189 train_acc 0.7250 test_acc 0.8000\n",
      "epoch 553 loss 0.6235 train_acc 0.7250 test_acc 0.8000\n",
      "epoch 554 loss 0.6265 train_acc 0.7250 test_acc 0.8000\n",
      "epoch 555 loss 0.6278 train_acc 0.7250 test_acc 0.8000\n",
      "epoch 556 loss 0.6276 train_acc 0.7250 test_acc 0.8000\n",
      "epoch 557 loss 0.6256 train_acc 0.7250 test_acc 0.8000\n",
      "epoch 558 loss 0.6222 train_acc 0.7250 test_acc 0.8000\n",
      "epoch 559 loss 0.6170 train_acc 0.7250 test_acc 0.8000\n",
      "epoch 560 loss 0.6106 train_acc 0.7333 test_acc 0.8000\n",
      "epoch 561 loss 0.6017 train_acc 0.7333 test_acc 0.8000\n",
      "epoch 562 loss 0.5919 train_acc 0.7333 test_acc 0.8000\n",
      "epoch 563 loss 0.5811 train_acc 0.7333 test_acc 0.8000\n",
      "epoch 564 loss 0.5683 train_acc 0.7333 test_acc 0.8000\n",
      "epoch 565 loss 0.5539 train_acc 0.7333 test_acc 0.8000\n",
      "epoch 566 loss 0.5387 train_acc 0.7583 test_acc 0.8000\n",
      "epoch 567 loss 0.5228 train_acc 0.7583 test_acc 0.8333\n",
      "epoch 568 loss 0.5049 train_acc 0.7667 test_acc 0.8333\n",
      "epoch 569 loss 0.4878 train_acc 0.7667 test_acc 0.8333\n",
      "epoch 570 loss 0.4674 train_acc 0.7750 test_acc 0.8333\n",
      "epoch 571 loss 0.4472 train_acc 0.7833 test_acc 0.8333\n",
      "epoch 572 loss 0.4288 train_acc 0.7917 test_acc 0.8333\n",
      "epoch 573 loss 0.4074 train_acc 0.8000 test_acc 0.9000\n",
      "epoch 574 loss 0.3881 train_acc 0.8083 test_acc 0.9000\n",
      "epoch 575 loss 0.3658 train_acc 0.8167 test_acc 0.9000\n",
      "epoch 576 loss 0.3439 train_acc 0.8250 test_acc 0.9000\n",
      "epoch 577 loss 0.3234 train_acc 0.8250 test_acc 0.9333\n",
      "epoch 578 loss 0.3025 train_acc 0.8417 test_acc 0.9333\n",
      "epoch 579 loss 0.2831 train_acc 0.8500 test_acc 0.9333\n",
      "epoch 580 loss 0.2644 train_acc 0.8583 test_acc 0.9333\n",
      "epoch 581 loss 0.2441 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 582 loss 0.2252 train_acc 0.8833 test_acc 0.9667\n",
      "epoch 583 loss 0.2110 train_acc 0.8833 test_acc 0.9667\n",
      "epoch 584 loss 0.1937 train_acc 0.9000 test_acc 0.9667\n",
      "epoch 585 loss 0.1777 train_acc 0.9167 test_acc 0.9667\n",
      "epoch 586 loss 0.1631 train_acc 0.9250 test_acc 0.9667\n",
      "epoch 587 loss 0.1511 train_acc 0.9250 test_acc 0.9667\n",
      "epoch 588 loss 0.1391 train_acc 0.9500 test_acc 0.9667\n",
      "epoch 589 loss 0.1299 train_acc 0.9417 test_acc 0.9667\n",
      "epoch 590 loss 0.1196 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 591 loss 0.1104 train_acc 0.9667 test_acc 0.9667\n",
      "epoch 592 loss 0.1038 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 593 loss 0.0985 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 594 loss 0.0931 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 595 loss 0.0904 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 596 loss 0.0881 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 597 loss 0.0867 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 598 loss 0.0869 train_acc 0.9833 test_acc 1.0000\n",
      "epoch 599 loss 0.0870 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 600 loss 0.0897 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 601 loss 0.0916 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 602 loss 0.0949 train_acc 0.9667 test_acc 0.9667\n",
      "epoch 603 loss 0.1001 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 604 loss 0.1048 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 605 loss 0.1108 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 606 loss 0.1163 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 607 loss 0.1261 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 608 loss 0.1316 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 609 loss 0.1408 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 610 loss 0.1503 train_acc 0.9500 test_acc 0.9333\n",
      "epoch 611 loss 0.1612 train_acc 0.9333 test_acc 0.9333\n",
      "epoch 612 loss 0.1715 train_acc 0.9333 test_acc 0.9000\n",
      "epoch 613 loss 0.1835 train_acc 0.9250 test_acc 0.9000\n",
      "epoch 614 loss 0.1946 train_acc 0.9083 test_acc 0.9000\n",
      "epoch 615 loss 0.2062 train_acc 0.9000 test_acc 0.8667\n",
      "epoch 616 loss 0.2192 train_acc 0.9000 test_acc 0.8333\n",
      "epoch 617 loss 0.2322 train_acc 0.9000 test_acc 0.8333\n",
      "epoch 618 loss 0.2466 train_acc 0.8833 test_acc 0.8000\n",
      "epoch 619 loss 0.2598 train_acc 0.8667 test_acc 0.7333\n",
      "epoch 620 loss 0.2733 train_acc 0.8583 test_acc 0.7333\n",
      "epoch 621 loss 0.2884 train_acc 0.8583 test_acc 0.7333\n",
      "epoch 622 loss 0.3024 train_acc 0.8500 test_acc 0.7333\n",
      "epoch 623 loss 0.3172 train_acc 0.8500 test_acc 0.7333\n",
      "epoch 624 loss 0.3296 train_acc 0.8500 test_acc 0.7333\n",
      "epoch 625 loss 0.3448 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 626 loss 0.3600 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 627 loss 0.3746 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 628 loss 0.3891 train_acc 0.8333 test_acc 0.7000\n",
      "epoch 629 loss 0.4025 train_acc 0.8333 test_acc 0.7000\n",
      "epoch 630 loss 0.4164 train_acc 0.8250 test_acc 0.7000\n",
      "epoch 631 loss 0.4297 train_acc 0.8250 test_acc 0.7000\n",
      "epoch 632 loss 0.4432 train_acc 0.8250 test_acc 0.7000\n",
      "epoch 633 loss 0.4558 train_acc 0.8250 test_acc 0.6667\n",
      "epoch 634 loss 0.4685 train_acc 0.8167 test_acc 0.6667\n",
      "epoch 635 loss 0.4797 train_acc 0.8083 test_acc 0.6667\n",
      "epoch 636 loss 0.4920 train_acc 0.8000 test_acc 0.6667\n",
      "epoch 637 loss 0.5031 train_acc 0.8000 test_acc 0.6667\n",
      "epoch 638 loss 0.5135 train_acc 0.8000 test_acc 0.6667\n",
      "epoch 639 loss 0.5227 train_acc 0.8000 test_acc 0.6667\n",
      "epoch 640 loss 0.5317 train_acc 0.8000 test_acc 0.6667\n",
      "epoch 641 loss 0.5401 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 642 loss 0.5477 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 643 loss 0.5544 train_acc 0.7833 test_acc 0.6333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 644 loss 0.5607 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 645 loss 0.5663 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 646 loss 0.5707 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 647 loss 0.5745 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 648 loss 0.5774 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 649 loss 0.5798 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 650 loss 0.5809 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 651 loss 0.5815 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 652 loss 0.5811 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 653 loss 0.5799 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 654 loss 0.5779 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 655 loss 0.5750 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 656 loss 0.5715 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 657 loss 0.5671 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 658 loss 0.5614 train_acc 0.7833 test_acc 0.6333\n",
      "epoch 659 loss 0.5560 train_acc 0.7833 test_acc 0.6667\n",
      "epoch 660 loss 0.5486 train_acc 0.8000 test_acc 0.6667\n",
      "epoch 661 loss 0.5405 train_acc 0.8000 test_acc 0.6667\n",
      "epoch 662 loss 0.5331 train_acc 0.8000 test_acc 0.6667\n",
      "epoch 663 loss 0.5243 train_acc 0.8000 test_acc 0.6667\n",
      "epoch 664 loss 0.5145 train_acc 0.8000 test_acc 0.6667\n",
      "epoch 665 loss 0.5041 train_acc 0.8083 test_acc 0.6667\n",
      "epoch 666 loss 0.4926 train_acc 0.8167 test_acc 0.6667\n",
      "epoch 667 loss 0.4819 train_acc 0.8250 test_acc 0.7000\n",
      "epoch 668 loss 0.4703 train_acc 0.8250 test_acc 0.7000\n",
      "epoch 669 loss 0.4577 train_acc 0.8250 test_acc 0.7000\n",
      "epoch 670 loss 0.4449 train_acc 0.8250 test_acc 0.7000\n",
      "epoch 671 loss 0.4323 train_acc 0.8250 test_acc 0.7000\n",
      "epoch 672 loss 0.4188 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 673 loss 0.4049 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 674 loss 0.3914 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 675 loss 0.3776 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 676 loss 0.3645 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 677 loss 0.3490 train_acc 0.8500 test_acc 0.7333\n",
      "epoch 678 loss 0.3341 train_acc 0.8500 test_acc 0.7333\n",
      "epoch 679 loss 0.3195 train_acc 0.8583 test_acc 0.7333\n",
      "epoch 680 loss 0.3060 train_acc 0.8583 test_acc 0.7333\n",
      "epoch 681 loss 0.2904 train_acc 0.8583 test_acc 0.7333\n",
      "epoch 682 loss 0.2777 train_acc 0.8583 test_acc 0.8000\n",
      "epoch 683 loss 0.2655 train_acc 0.8833 test_acc 0.8333\n",
      "epoch 684 loss 0.2522 train_acc 0.8917 test_acc 0.8333\n",
      "epoch 685 loss 0.2393 train_acc 0.9000 test_acc 0.8333\n",
      "epoch 686 loss 0.2268 train_acc 0.9000 test_acc 0.8667\n",
      "epoch 687 loss 0.2125 train_acc 0.9000 test_acc 0.9000\n",
      "epoch 688 loss 0.2003 train_acc 0.9167 test_acc 0.9000\n",
      "epoch 689 loss 0.1909 train_acc 0.9250 test_acc 0.9333\n",
      "epoch 690 loss 0.1779 train_acc 0.9333 test_acc 0.9333\n",
      "epoch 691 loss 0.1674 train_acc 0.9333 test_acc 0.9333\n",
      "epoch 692 loss 0.1574 train_acc 0.9417 test_acc 0.9333\n",
      "epoch 693 loss 0.1489 train_acc 0.9500 test_acc 0.9333\n",
      "epoch 694 loss 0.1392 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 695 loss 0.1305 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 696 loss 0.1227 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 697 loss 0.1154 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 698 loss 0.1076 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 699 loss 0.1014 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 700 loss 0.0968 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 701 loss 0.0915 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 702 loss 0.0866 train_acc 0.9667 test_acc 0.9667\n",
      "epoch 703 loss 0.0817 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 704 loss 0.0793 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 705 loss 0.0760 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 706 loss 0.0735 train_acc 0.9833 test_acc 1.0000\n",
      "epoch 707 loss 0.0732 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 708 loss 0.0709 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 709 loss 0.0701 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 710 loss 0.0702 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 711 loss 0.0711 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 712 loss 0.0727 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 713 loss 0.0756 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 714 loss 0.0771 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 715 loss 0.0814 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 716 loss 0.0854 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 717 loss 0.0903 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 718 loss 0.0961 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 719 loss 0.1020 train_acc 0.9417 test_acc 0.9667\n",
      "epoch 720 loss 0.1094 train_acc 0.9417 test_acc 0.9667\n",
      "epoch 721 loss 0.1171 train_acc 0.9500 test_acc 0.9667\n",
      "epoch 722 loss 0.1255 train_acc 0.9417 test_acc 0.9667\n",
      "epoch 723 loss 0.1329 train_acc 0.9250 test_acc 0.9667\n",
      "epoch 724 loss 0.1428 train_acc 0.9250 test_acc 0.9667\n",
      "epoch 725 loss 0.1531 train_acc 0.9250 test_acc 0.9667\n",
      "epoch 726 loss 0.1632 train_acc 0.9167 test_acc 0.9667\n",
      "epoch 727 loss 0.1751 train_acc 0.9083 test_acc 0.9667\n",
      "epoch 728 loss 0.1859 train_acc 0.9000 test_acc 0.9667\n",
      "epoch 729 loss 0.1977 train_acc 0.8833 test_acc 0.9333\n",
      "epoch 730 loss 0.2097 train_acc 0.8833 test_acc 0.9333\n",
      "epoch 731 loss 0.2242 train_acc 0.8750 test_acc 0.9333\n",
      "epoch 732 loss 0.2350 train_acc 0.8750 test_acc 0.9333\n",
      "epoch 733 loss 0.2488 train_acc 0.8750 test_acc 0.9333\n",
      "epoch 734 loss 0.2617 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 735 loss 0.2759 train_acc 0.8583 test_acc 0.9333\n",
      "epoch 736 loss 0.2874 train_acc 0.8583 test_acc 0.9333\n",
      "epoch 737 loss 0.3020 train_acc 0.8500 test_acc 0.9333\n",
      "epoch 738 loss 0.3148 train_acc 0.8417 test_acc 0.9333\n",
      "epoch 739 loss 0.3289 train_acc 0.8333 test_acc 0.9333\n",
      "epoch 740 loss 0.3401 train_acc 0.8333 test_acc 0.9000\n",
      "epoch 741 loss 0.3521 train_acc 0.8333 test_acc 0.9000\n",
      "epoch 742 loss 0.3655 train_acc 0.8333 test_acc 0.9000\n",
      "epoch 743 loss 0.3779 train_acc 0.8250 test_acc 0.9000\n",
      "epoch 744 loss 0.3892 train_acc 0.8250 test_acc 0.9000\n",
      "epoch 745 loss 0.4008 train_acc 0.8167 test_acc 0.9000\n",
      "epoch 746 loss 0.4119 train_acc 0.8167 test_acc 0.9000\n",
      "epoch 747 loss 0.4213 train_acc 0.8083 test_acc 0.9000\n",
      "epoch 748 loss 0.4321 train_acc 0.8083 test_acc 0.8667\n",
      "epoch 749 loss 0.4407 train_acc 0.8083 test_acc 0.8667\n",
      "epoch 750 loss 0.4483 train_acc 0.8000 test_acc 0.8667\n",
      "epoch 751 loss 0.4564 train_acc 0.8000 test_acc 0.8667\n",
      "epoch 752 loss 0.4634 train_acc 0.8000 test_acc 0.8667\n",
      "epoch 753 loss 0.4692 train_acc 0.8000 test_acc 0.8667\n",
      "epoch 754 loss 0.4746 train_acc 0.8000 test_acc 0.8333\n",
      "epoch 755 loss 0.4791 train_acc 0.8000 test_acc 0.8333\n",
      "epoch 756 loss 0.4827 train_acc 0.8000 test_acc 0.8333\n",
      "epoch 757 loss 0.4854 train_acc 0.8000 test_acc 0.8333\n",
      "epoch 758 loss 0.4872 train_acc 0.8000 test_acc 0.8333\n",
      "epoch 759 loss 0.4882 train_acc 0.8000 test_acc 0.8333\n",
      "epoch 760 loss 0.4884 train_acc 0.8000 test_acc 0.8333\n",
      "epoch 761 loss 0.4876 train_acc 0.8000 test_acc 0.8333\n",
      "epoch 762 loss 0.4859 train_acc 0.8000 test_acc 0.8333\n",
      "epoch 763 loss 0.4834 train_acc 0.8000 test_acc 0.8333\n",
      "epoch 764 loss 0.4799 train_acc 0.8000 test_acc 0.8667\n",
      "epoch 765 loss 0.4761 train_acc 0.8000 test_acc 0.8667\n",
      "epoch 766 loss 0.4707 train_acc 0.8000 test_acc 0.8667\n",
      "epoch 767 loss 0.4651 train_acc 0.8000 test_acc 0.8667\n",
      "epoch 768 loss 0.4583 train_acc 0.8000 test_acc 0.8667\n",
      "epoch 769 loss 0.4507 train_acc 0.8083 test_acc 0.8667\n",
      "epoch 770 loss 0.4428 train_acc 0.8083 test_acc 0.9000\n",
      "epoch 771 loss 0.4348 train_acc 0.8083 test_acc 0.9000\n",
      "epoch 772 loss 0.4242 train_acc 0.8083 test_acc 0.9000\n",
      "epoch 773 loss 0.4139 train_acc 0.8167 test_acc 0.9000\n",
      "epoch 774 loss 0.4034 train_acc 0.8167 test_acc 0.9000\n",
      "epoch 775 loss 0.3931 train_acc 0.8250 test_acc 0.9000\n",
      "epoch 776 loss 0.3812 train_acc 0.8250 test_acc 0.9000\n",
      "epoch 777 loss 0.3689 train_acc 0.8333 test_acc 0.9000\n",
      "epoch 778 loss 0.3569 train_acc 0.8333 test_acc 0.9333\n",
      "epoch 779 loss 0.3453 train_acc 0.8333 test_acc 0.9333\n",
      "epoch 780 loss 0.3314 train_acc 0.8417 test_acc 0.9333\n",
      "epoch 781 loss 0.3175 train_acc 0.8417 test_acc 0.9333\n",
      "epoch 782 loss 0.3043 train_acc 0.8583 test_acc 0.9333\n",
      "epoch 783 loss 0.2922 train_acc 0.8583 test_acc 0.9333\n",
      "epoch 784 loss 0.2786 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 785 loss 0.2663 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 786 loss 0.2521 train_acc 0.8750 test_acc 0.9333\n",
      "epoch 787 loss 0.2401 train_acc 0.8750 test_acc 0.9333\n",
      "epoch 788 loss 0.2274 train_acc 0.8750 test_acc 0.9333\n",
      "epoch 789 loss 0.2148 train_acc 0.8833 test_acc 0.9333\n",
      "epoch 790 loss 0.2024 train_acc 0.8917 test_acc 0.9667\n",
      "epoch 791 loss 0.1893 train_acc 0.9000 test_acc 0.9667\n",
      "epoch 792 loss 0.1795 train_acc 0.9167 test_acc 0.9667\n",
      "epoch 793 loss 0.1685 train_acc 0.9250 test_acc 0.9667\n",
      "epoch 794 loss 0.1581 train_acc 0.9250 test_acc 0.9667\n",
      "epoch 795 loss 0.1466 train_acc 0.9250 test_acc 0.9667\n",
      "epoch 796 loss 0.1377 train_acc 0.9333 test_acc 0.9667\n",
      "epoch 797 loss 0.1296 train_acc 0.9333 test_acc 0.9667\n",
      "epoch 798 loss 0.1209 train_acc 0.9417 test_acc 0.9667\n",
      "epoch 799 loss 0.1125 train_acc 0.9417 test_acc 0.9667\n",
      "epoch 800 loss 0.1055 train_acc 0.9417 test_acc 0.9667\n",
      "epoch 801 loss 0.1001 train_acc 0.9417 test_acc 0.9667\n",
      "epoch 802 loss 0.0938 train_acc 0.9500 test_acc 0.9667\n",
      "epoch 803 loss 0.0872 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 804 loss 0.0833 train_acc 0.9667 test_acc 0.9667\n",
      "epoch 805 loss 0.0792 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 806 loss 0.0753 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 807 loss 0.0732 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 808 loss 0.0705 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 809 loss 0.0678 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 810 loss 0.0680 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 811 loss 0.0675 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 812 loss 0.0672 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 813 loss 0.0669 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 814 loss 0.0675 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 815 loss 0.0698 train_acc 0.9833 test_acc 1.0000\n",
      "epoch 816 loss 0.0706 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 817 loss 0.0731 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 818 loss 0.0764 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 819 loss 0.0789 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 820 loss 0.0824 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 821 loss 0.0864 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 822 loss 0.0901 train_acc 0.9583 test_acc 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 823 loss 0.0953 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 824 loss 0.0997 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 825 loss 0.1059 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 826 loss 0.1102 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 827 loss 0.1155 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 828 loss 0.1222 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 829 loss 0.1280 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 830 loss 0.1340 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 831 loss 0.1409 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 832 loss 0.1478 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 833 loss 0.1552 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 834 loss 0.1639 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 835 loss 0.1711 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 836 loss 0.1794 train_acc 0.9417 test_acc 0.9333\n",
      "epoch 837 loss 0.1870 train_acc 0.9417 test_acc 0.9333\n",
      "epoch 838 loss 0.1954 train_acc 0.9333 test_acc 0.9333\n",
      "epoch 839 loss 0.2025 train_acc 0.9250 test_acc 0.9333\n",
      "epoch 840 loss 0.2123 train_acc 0.9167 test_acc 0.9333\n",
      "epoch 841 loss 0.2208 train_acc 0.9167 test_acc 0.9333\n",
      "epoch 842 loss 0.2294 train_acc 0.9083 test_acc 0.9000\n",
      "epoch 843 loss 0.2387 train_acc 0.9083 test_acc 0.9000\n",
      "epoch 844 loss 0.2474 train_acc 0.8917 test_acc 0.9000\n",
      "epoch 845 loss 0.2552 train_acc 0.8917 test_acc 0.9000\n",
      "epoch 846 loss 0.2658 train_acc 0.8833 test_acc 0.8333\n",
      "epoch 847 loss 0.2734 train_acc 0.8833 test_acc 0.8333\n",
      "epoch 848 loss 0.2820 train_acc 0.8833 test_acc 0.8333\n",
      "epoch 849 loss 0.2911 train_acc 0.8833 test_acc 0.8333\n",
      "epoch 850 loss 0.2998 train_acc 0.8833 test_acc 0.8333\n",
      "epoch 851 loss 0.3084 train_acc 0.8750 test_acc 0.8333\n",
      "epoch 852 loss 0.3162 train_acc 0.8750 test_acc 0.8333\n",
      "epoch 853 loss 0.3246 train_acc 0.8583 test_acc 0.8333\n",
      "epoch 854 loss 0.3324 train_acc 0.8500 test_acc 0.8333\n",
      "epoch 855 loss 0.3406 train_acc 0.8417 test_acc 0.8000\n",
      "epoch 856 loss 0.3479 train_acc 0.8417 test_acc 0.7667\n",
      "epoch 857 loss 0.3546 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 858 loss 0.3622 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 859 loss 0.3681 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 860 loss 0.3753 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 861 loss 0.3809 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 862 loss 0.3863 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 863 loss 0.3918 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 864 loss 0.3968 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 865 loss 0.4011 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 866 loss 0.4051 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 867 loss 0.4085 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 868 loss 0.4120 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 869 loss 0.4147 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 870 loss 0.4171 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 871 loss 0.4187 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 872 loss 0.4205 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 873 loss 0.4214 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 874 loss 0.4216 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 875 loss 0.4218 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 876 loss 0.4214 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 877 loss 0.4206 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 878 loss 0.4192 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 879 loss 0.4175 train_acc 0.8333 test_acc 0.7333\n",
      "epoch 880 loss 0.4153 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 881 loss 0.4130 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 882 loss 0.4097 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 883 loss 0.4063 train_acc 0.8417 test_acc 0.7333\n",
      "epoch 884 loss 0.4024 train_acc 0.8500 test_acc 0.7333\n",
      "epoch 885 loss 0.3985 train_acc 0.8500 test_acc 0.7333\n",
      "epoch 886 loss 0.3936 train_acc 0.8500 test_acc 0.7333\n",
      "epoch 887 loss 0.3886 train_acc 0.8583 test_acc 0.7333\n",
      "epoch 888 loss 0.3839 train_acc 0.8583 test_acc 0.7333\n",
      "epoch 889 loss 0.3774 train_acc 0.8583 test_acc 0.7333\n",
      "epoch 890 loss 0.3717 train_acc 0.8583 test_acc 0.7333\n",
      "epoch 891 loss 0.3662 train_acc 0.8583 test_acc 0.7333\n",
      "epoch 892 loss 0.3600 train_acc 0.8583 test_acc 0.7333\n",
      "epoch 893 loss 0.3527 train_acc 0.8583 test_acc 0.7333\n",
      "epoch 894 loss 0.3457 train_acc 0.8583 test_acc 0.7333\n",
      "epoch 895 loss 0.3387 train_acc 0.8583 test_acc 0.8000\n",
      "epoch 896 loss 0.3318 train_acc 0.8583 test_acc 0.8333\n",
      "epoch 897 loss 0.3232 train_acc 0.8583 test_acc 0.8333\n",
      "epoch 898 loss 0.3159 train_acc 0.8583 test_acc 0.8333\n",
      "epoch 899 loss 0.3076 train_acc 0.8750 test_acc 0.8333\n",
      "epoch 900 loss 0.3008 train_acc 0.8917 test_acc 0.8333\n",
      "epoch 901 loss 0.2928 train_acc 0.8917 test_acc 0.8333\n",
      "epoch 902 loss 0.2845 train_acc 0.9000 test_acc 0.8333\n",
      "epoch 903 loss 0.2756 train_acc 0.9000 test_acc 0.8333\n",
      "epoch 904 loss 0.2685 train_acc 0.9000 test_acc 0.8333\n",
      "epoch 905 loss 0.2601 train_acc 0.9000 test_acc 0.8333\n",
      "epoch 906 loss 0.2518 train_acc 0.9000 test_acc 0.9000\n",
      "epoch 907 loss 0.2436 train_acc 0.9000 test_acc 0.9000\n",
      "epoch 908 loss 0.2356 train_acc 0.9083 test_acc 0.9000\n",
      "epoch 909 loss 0.2276 train_acc 0.9167 test_acc 0.9000\n",
      "epoch 910 loss 0.2203 train_acc 0.9167 test_acc 0.9333\n",
      "epoch 911 loss 0.2125 train_acc 0.9167 test_acc 0.9333\n",
      "epoch 912 loss 0.2047 train_acc 0.9250 test_acc 0.9333\n",
      "epoch 913 loss 0.1969 train_acc 0.9250 test_acc 0.9333\n",
      "epoch 914 loss 0.1892 train_acc 0.9417 test_acc 0.9333\n",
      "epoch 915 loss 0.1826 train_acc 0.9417 test_acc 0.9333\n",
      "epoch 916 loss 0.1749 train_acc 0.9417 test_acc 0.9333\n",
      "epoch 917 loss 0.1680 train_acc 0.9500 test_acc 0.9333\n",
      "epoch 918 loss 0.1616 train_acc 0.9500 test_acc 0.9333\n",
      "epoch 919 loss 0.1550 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 920 loss 0.1490 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 921 loss 0.1422 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 922 loss 0.1354 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 923 loss 0.1307 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 924 loss 0.1244 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 925 loss 0.1190 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 926 loss 0.1143 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 927 loss 0.1100 train_acc 0.9583 test_acc 0.9333\n",
      "epoch 928 loss 0.1052 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 929 loss 0.1000 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 930 loss 0.0952 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 931 loss 0.0911 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 932 loss 0.0873 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 933 loss 0.0849 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 934 loss 0.0815 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 935 loss 0.0783 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 936 loss 0.0740 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 937 loss 0.0720 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 938 loss 0.0699 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 939 loss 0.0668 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 940 loss 0.0648 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 941 loss 0.0629 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 942 loss 0.0623 train_acc 0.9833 test_acc 1.0000\n",
      "epoch 943 loss 0.0607 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 944 loss 0.0597 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 945 loss 0.0597 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 946 loss 0.0588 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 947 loss 0.0586 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 948 loss 0.0586 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 949 loss 0.0591 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 950 loss 0.0600 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 951 loss 0.0613 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 952 loss 0.0627 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 953 loss 0.0643 train_acc 0.9750 test_acc 0.9667\n",
      "epoch 954 loss 0.0671 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 955 loss 0.0691 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 956 loss 0.0719 train_acc 0.9833 test_acc 0.9667\n",
      "epoch 957 loss 0.0747 train_acc 0.9667 test_acc 0.9667\n",
      "epoch 958 loss 0.0781 train_acc 0.9667 test_acc 0.9667\n",
      "epoch 959 loss 0.0822 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 960 loss 0.0866 train_acc 0.9583 test_acc 0.9667\n",
      "epoch 961 loss 0.0899 train_acc 0.9500 test_acc 0.9667\n",
      "epoch 962 loss 0.0953 train_acc 0.9500 test_acc 0.9667\n",
      "epoch 963 loss 0.1011 train_acc 0.9417 test_acc 0.9667\n",
      "epoch 964 loss 0.1057 train_acc 0.9417 test_acc 0.9667\n",
      "epoch 965 loss 0.1119 train_acc 0.9333 test_acc 0.9667\n",
      "epoch 966 loss 0.1179 train_acc 0.9333 test_acc 0.9667\n",
      "epoch 967 loss 0.1244 train_acc 0.9333 test_acc 0.9667\n",
      "epoch 968 loss 0.1301 train_acc 0.9417 test_acc 0.9667\n",
      "epoch 969 loss 0.1376 train_acc 0.9417 test_acc 0.9667\n",
      "epoch 970 loss 0.1425 train_acc 0.9333 test_acc 0.9667\n",
      "epoch 971 loss 0.1507 train_acc 0.9333 test_acc 0.9667\n",
      "epoch 972 loss 0.1576 train_acc 0.9333 test_acc 0.9667\n",
      "epoch 973 loss 0.1663 train_acc 0.9167 test_acc 0.9667\n",
      "epoch 974 loss 0.1728 train_acc 0.9167 test_acc 0.9667\n",
      "epoch 975 loss 0.1810 train_acc 0.9167 test_acc 0.9667\n",
      "epoch 976 loss 0.1898 train_acc 0.9167 test_acc 0.9667\n",
      "epoch 977 loss 0.1975 train_acc 0.9167 test_acc 0.9667\n",
      "epoch 978 loss 0.2057 train_acc 0.9167 test_acc 0.9667\n",
      "epoch 979 loss 0.2143 train_acc 0.9000 test_acc 0.9667\n",
      "epoch 980 loss 0.2213 train_acc 0.8917 test_acc 0.9333\n",
      "epoch 981 loss 0.2297 train_acc 0.8833 test_acc 0.9333\n",
      "epoch 982 loss 0.2376 train_acc 0.8750 test_acc 0.9333\n",
      "epoch 983 loss 0.2457 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 984 loss 0.2539 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 985 loss 0.2611 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 986 loss 0.2695 train_acc 0.8667 test_acc 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 987 loss 0.2763 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 988 loss 0.2836 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 989 loss 0.2910 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 990 loss 0.2981 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 991 loss 0.3048 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 992 loss 0.3110 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 993 loss 0.3174 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 994 loss 0.3229 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 995 loss 0.3282 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 996 loss 0.3334 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 997 loss 0.3384 train_acc 0.8667 test_acc 0.9333\n",
      "epoch 998 loss 0.3428 train_acc 0.8583 test_acc 0.9333\n",
      "epoch 999 loss 0.3462 train_acc 0.8583 test_acc 0.9333\n",
      "epoch 1000 loss 0.3496 train_acc 0.8583 test_acc 0.9333\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    num_epochs=1000,\n",
    "    batch_size=batch_size,\n",
    "    net = net,\n",
    "    loss = loss,\n",
    "    train_data_iter=train_data_iter,\n",
    "    test_data_iter=test_data_iter,\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
