{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T12:09:59.727875Z",
     "start_time": "2019-11-19T12:09:59.142837Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# http://tangshusen.me/Dive-into-DL-PyTorch/#/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch**\n",
    "- torch.utils.data模块提供了有关数据处理的工具\n",
    "- torch.nn模块定义了大量神经网络的层\n",
    "- torch.nn.init模块定义了各种初始化方法\n",
    "- torch.optim模块提供了模型参数初始化的各种方法。\n",
    "\n",
    "\n",
    "**torchvision**\n",
    "- torchvision.datasets: 一些加载数据的函数及常用的数据集接口；\n",
    "- torchvision.models: 包含常用的模型结构（含预训练模型），例如AlexNet、VGG、ResNet等；\n",
    "- torchvision.transforms: 常用的图片变换，例如裁剪、旋转等；\n",
    "- torchvision.utils: 其他的一些有用的方法。\n",
    "\n",
    "\n",
    "**常用操作**\n",
    "- torch.cat\n",
    "- torch.mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensor 操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T12:10:01.691471Z",
     "start_time": "2019-11-19T12:10:01.680216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2.]\n",
      "tensor([1., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# numpy(), torch.from_numpy()\n",
    "print(torch.tensor([1.,2.]).numpy())\n",
    "print(torch.from_numpy(np.array([1.,2.])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T12:10:01.772123Z",
     "start_time": "2019-11-19T12:10:01.765923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.])\n",
      "tensor([[1., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# unsqueeze\n",
    "print(torch.tensor([1.,2.]))\n",
    "print(torch.tensor([1.,2.]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T12:10:01.863069Z",
     "start_time": "2019-11-19T12:10:01.850808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.],\n",
      "        [2., 3.]])\n",
      "tensor(6.)\n",
      "tensor([2., 4.])\n",
      "tensor([1., 5.])\n",
      "\n",
      "tensor([[2., 4.]])\n",
      "tensor([[1.],\n",
      "        [5.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(range(4), dtype=torch.float32).view(2,2)\n",
    "print(a)\n",
    "print(a.sum())\n",
    "print(a.sum(dim=0))\n",
    "print(a.sum(dim=1))\n",
    "print()\n",
    "print(a.sum(dim=0, keepdim=True))\n",
    "print(a.sum(dim=1, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T12:10:01.947702Z",
     "start_time": "2019-11-19T12:10:01.935271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n",
      "tensor([[1.],\n",
      "        [3.],\n",
      "        [7.]])\n",
      "tensor([[3., 4., 8.]])\n",
      "tensor([[3., 4., 8.],\n",
      "        [0., 1., 5.]])\n"
     ]
    }
   ],
   "source": [
    "# gather\n",
    "a = torch.tensor(range(9), dtype=torch.float32).view(3,3)\n",
    "print(a)\n",
    "print(a.gather(1, torch.tensor([[1],[0], [1]])))\n",
    "print(a.gather(0, torch.tensor([[1, 1, 2]]))) # out[i][j] = input[index[i][j]][j]\n",
    "print(a.gather(0, torch.tensor([[1, 1, 2], [0, 0, 1]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T12:10:02.033451Z",
     "start_time": "2019-11-19T12:10:02.022218Z"
    }
   },
   "outputs": [],
   "source": [
    "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\n",
    "y = torch.LongTensor([0, 2])\n",
    "y_hat.gather(1, y.view(-1, 1))\n",
    "torch.gather??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习率的调整\n",
    "\n",
    "```\n",
    "optimizer =optim.SGD([\n",
    "    # 如果对某个参数不指定学习率，就使用最外层的默认学习率\n",
    "    {'params': net.subnet1.parameters()}, # lr=0.03\n",
    "    {'params': net.subnet2.parameters(), 'lr': 0.01}\n",
    "], lr=0.03)\n",
    "```\n",
    "有时候我们不想让学习率固定成一个常数，那如何调整学习率呢？主要有两种做法。一种是修改optimizer.param_groups中对应的学习率，另一种是更简单也是较为推荐的做法——新建优化器，由于optimizer十分轻量级，构建开销很小，故而可以构建新的optimizer。但是后者对于使用动量的优化器（如Adam），会丢失动量等状态信息，可能会造成损失函数的收敛出现震荡等情况。\n",
    "\n",
    "```\n",
    "# 调整学习率\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] *= 0.1 # 学习率为之前的0.1倍\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T12:10:02.295824Z",
     "start_time": "2019-11-19T12:10:02.285022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 写法一\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 1)\n",
    ")\n",
    "\n",
    "# 写法二\n",
    "net = torch.nn.Sequential()\n",
    "net.add_module('linear', torch.nn.Linear(2, 1))\n",
    "# net.add_module ......\n",
    "\n",
    "# 写法三\n",
    "from collections import OrderedDict\n",
    "net = torch.nn.Sequential(OrderedDict([\n",
    "    ('linear', torch.nn.Linear(2, 1))\n",
    "    # ......\n",
    "]))\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构造复杂模型\n",
    "\n",
    "- 可以通过继承Module类来构造模型。\n",
    "- Sequential、ModuleList、ModuleDict类都继承自Module类。\n",
    "- 与Sequential不同，ModuleList和ModuleDict并没有定义一个完整的网络，它们只是将不同的模块存放在一起，需要自己定义forward函数。\n",
    "- 虽然Sequential等类可以使模型构造更加简单，但直接继承Module类可以极大地拓展模型构造的灵活性。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数的相关\n",
    "\n",
    "net[0] 这样根据下标访问子模块的写法只有当 net 是个 ModuleList 或者 Sequential 实例时才可以"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T12:17:17.215822Z",
     "start_time": "2019-11-19T12:17:17.208859Z"
    }
   },
   "outputs": [],
   "source": [
    "class LinearNet(torch.nn.Module):\n",
    "    def __init__(self, input, output):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input, output, bias=True)\n",
    "        self.w1 = torch.randn(4,3)\n",
    "        self.w2 = torch.nn.Parameter(torch.randn(4,3))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "net = torch.nn.Sequential(LinearNet(4,3), torch.nn.ReLU(), torch.nn.Linear(3,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T12:17:18.439129Z",
     "start_time": "2019-11-19T12:17:18.436651Z"
    }
   },
   "source": [
    "#### 访问参数\n",
    "\n",
    "`torch.nn.Parameter` 是 `tensor` 的子类, 并且会自动被添加到模型的参数列表 `net.named_parameters()` 或 `net.parameters()` 里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T12:29:41.178700Z",
     "start_time": "2019-11-19T12:29:41.169112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.3584,  0.5445,  0.6224],\n",
      "        [ 1.6710,  0.4676,  1.0141],\n",
      "        [-0.1355,  1.3659, -0.2936],\n",
      "        [ 0.0757,  0.5898, -1.4875]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3151, -0.3208,  0.3802,  0.0899],\n",
      "        [-0.3079,  0.3529,  0.3170,  0.4978],\n",
      "        [ 0.4353, -0.3208, -0.4605,  0.1064]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0731,  0.1902, -0.0534], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2613, -0.4719, -0.1674]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2197], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T12:29:57.898328Z",
     "start_time": "2019-11-19T12:29:57.893044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): LinearNet(\n",
      "    (linear): Linear(in_features=4, out_features=3, bias=True)\n",
      "  )\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n",
      "0.w2 torch.Size([4, 3])\n",
      "0.linear.weight torch.Size([3, 4])\n",
      "0.linear.bias torch.Size([3])\n",
      "2.weight torch.Size([1, 3])\n",
      "2.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(net)\n",
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T12:31:36.667787Z",
     "start_time": "2019-11-19T12:31:36.662321Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].w2.shape\n",
    "net[0].linear.weight.shape\n",
    "net[0].linear.bias.shape\n",
    "net[2].weight.shape\n",
    "net[2].bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T12:09:55.599813Z",
     "start_time": "2019-11-19T12:09:55.596534Z"
    }
   },
   "source": [
    "#### 初始化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T12:32:40.556536Z",
     "start_time": "2019-11-19T12:32:40.548911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init.normal_(net[0].w2, 0., 0.1)\n",
    "torch.nn.init.constant_(net[2].bias, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T12:34:54.300967Z",
     "start_time": "2019-11-19T12:34:54.292132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.linear.weight tensor([[-0.0026, -0.0153,  0.0033,  0.0024],\n",
      "        [-0.0085,  0.0047,  0.0049, -0.0101],\n",
      "        [ 0.0018,  0.0073, -0.0047, -0.0097]])\n",
      "0.linear.bias tensor([0., 0., 0.])\n",
      "2.weight tensor([[ 0.0027,  0.0004, -0.0091]])\n",
      "2.bias tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        torch.nn.init.normal_(param, mean=0, std=0.01)\n",
    "        print(name, param.data)\n",
    "    if 'bias' in name:\n",
    "        torch.nn.init.constant_(param, val=0)\n",
    "        print(name, param.data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义初始化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T12:37:39.033631Z",
     "start_time": "2019-11-19T12:37:39.030324Z"
    }
   },
   "outputs": [],
   "source": [
    "def normal_(tensor, mean=0, std=1):\n",
    "    with torch.no_grad():\n",
    "        return tensor.normal_(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T12:37:39.423053Z",
     "start_time": "2019-11-19T12:37:39.410376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.linear.weight tensor([[ 8.2923,  0.0000,  0.0000, -0.0000],\n",
      "        [ 0.0000,  0.0000,  8.5411,  8.0008],\n",
      "        [ 6.9095,  5.2381, -0.0000, -6.1619]])\n",
      "2.weight tensor([[8.7914, 0.0000, 8.0843]])\n"
     ]
    }
   ],
   "source": [
    "def init_weight_(tensor):\n",
    "    with torch.no_grad():\n",
    "        tensor.uniform_(-10, 10)\n",
    "        tensor *= (tensor.abs() >= 5).float()\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init_weight_(param)\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-19T12:38:19.681244Z",
     "start_time": "2019-11-19T12:38:19.674731Z"
    }
   },
   "source": [
    "#### 共享参数\n",
    "\n",
    "> 因为模型参数里包含了梯度，所以在反向传播计算时，这些共享的参数的梯度是累加的:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T08:49:03.625266Z",
     "start_time": "2019-11-18T08:49:03.622318Z"
    }
   },
   "source": [
    "#### 正则\n",
    "\n",
    "```\n",
    "# 初始化参数\n",
    "nn.init.normal_(net.weight, mean=0, std=1)\n",
    "nn.init.normal_(net.bias, mean=0, std=1)\n",
    "    \n",
    "# 定义优化器\n",
    "optimizer_w = torch.optim.SGD(params=[net.weight], lr=lr, weight_decay=wd) # 对权重参数衰减\n",
    "optimizer_b = torch.optim.SGD(params=[net.bias], lr=lr)  # 不对偏差参数衰减\n",
    "\n",
    "#训练\n",
    "    optimizer_w.zero_grad()\n",
    "    optimizer_b.zero_grad()\n",
    "    l = ...\n",
    "    l.backward()\n",
    "    \n",
    "    optimizer_w.step()\n",
    "    optimizer_b.step()\n",
    "```\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练的过程\n",
    "\n",
    "```\n",
    "optimizer.zero_grad() # 梯度清零，等价于net.zero_grad()\n",
    "output = net(X)\n",
    "l = loss(output, y.view(output.shape))\n",
    "l.backward()\n",
    "optimizer.step()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T09:53:48.535084Z",
     "start_time": "2019-11-17T09:53:48.527004Z"
    }
   },
   "source": [
    "### 其它\n",
    "\n",
    "注意：torch.nn仅支持输入一个batch的样本不支持单个样本输入，如果只有单个样本，可使用input.unsqueeze(0)来添加一维。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T09:54:31.381070Z",
     "start_time": "2019-11-17T09:54:31.373078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.])\n",
      "tensor([[1., 2.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([1.,2.]))\n",
    "print(torch.tensor([1.,2.]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 修改数值, 不影响梯度的方式\n",
    "```\n",
    "#1.\n",
    "with torch.no_grad():\n",
    "    ...\n",
    "\n",
    "#2.\n",
    "param.data.init_()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:10:17.585628Z",
     "start_time": "2019-11-20T10:10:17.577023Z"
    }
   },
   "source": [
    "### tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 两个参数矩阵计算后求和 等价化\n",
    "\n",
    "XW_x+HW_h 等价于 (X, H 列合并)(W_x, W_h 行合并)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:14:07.053400Z",
     "start_time": "2019-11-20T10:14:07.048167Z"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.randn(3,1)\n",
    "W_x = torch.randn(1,4)\n",
    "\n",
    "H = torch.randn(3,4)\n",
    "W_h = torch.randn(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:14:32.187821Z",
     "start_time": "2019-11-20T10:14:32.171753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5841, -0.5694,  1.6718, -0.9662],\n",
       "        [ 0.3362, -0.4847,  2.6763, -2.8878],\n",
       "        [-0.5670,  1.0877, -2.4146, -0.8737]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(X, W_x) + torch.mm(H, W_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-20T10:16:11.323964Z",
     "start_time": "2019-11-20T10:16:11.314463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5841, -0.5694,  1.6718, -0.9662],\n",
       "        [ 0.3362, -0.4847,  2.6763, -2.8878],\n",
       "        [-0.5670,  1.0877, -2.4146, -0.8737]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(\n",
    "    torch.cat([X, H], dim=1), torch.cat([W_x, W_h], dim=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T14:36:11.465083Z",
     "start_time": "2019-11-21T14:36:11.427343Z"
    }
   },
   "source": [
    "### scatter & gather\n",
    "- https://pytorch.org/docs/stable/tensors.html?highlight=scatter#torch.Tensor.scatter_\n",
    "- https://pytorch.org/docs/stable/tensors.html?highlight=scatter#torch.Tensor.gather_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T14:49:43.945172Z",
     "start_time": "2019-11-21T14:49:43.918805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7000],\n",
       "        [0.5000],\n",
       "        [0.8000]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=torch.tensor([0,1,2])\n",
    "y_hat = torch.tensor([\n",
    "    [0.7,0.2,0.1],\n",
    "    [0.2,0.5,0.3],\n",
    "    [0.1,0.1,0.8],\n",
    "])\n",
    "y_hat.gather(dim=1, index = y.view(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T14:52:18.645395Z",
     "start_time": "2019-11-21T14:52:18.638777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([0,1,2])\n",
    "torch.zeros(3,10).scatter(1, x.view(-1,1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
